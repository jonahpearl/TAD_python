{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TAD_Week3_etASAdemo_ng_student.ipynb","provenance":[{"file_id":"1u-_JV6n8CZ1IleQ_RmvQ-Z1PFPu5-OL3","timestamp":1631702462574}],"collapsed_sections":[],"authorship_tag":"ABX9TyMYvjhjmzaf5PpWjcy2XT/J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1N_9rxPwRS8r"},"source":["# Bootstrap example for Stroke data from pp. 3-5 of Efron & Tibshirani\n","\n","RTB wrote it 29 October 2016 (derived from BS_ex1.m)\n","RTB modified it 30 Jan 2017: combined etASAhypoth.m and etASAstats.m into\n","one file that is modular for my stats class.\n","RTB modified it to emphasize stroke data (13 September 2018). ERBB translated to Python 08 September 2021. \n","\n","**The scenario**:\n","\n"," A study was done to see if low-dose aspirin would prevent\n","heart attacks in healthy middle-aged men. The study design was optimal:\n","controlled, randomized, double-blind. Subjects were randomly assigned to\n","receive aspirin (ASA) or placebo. The summary statistics:\n","\n","aspirin group (n=11037): 104 heart attacks (MI); 10933 no MI\n","placebo group (n=11034): 189 heart attacks; 10845 no MI\n","\n","Scientific question #1: Does aspirin help to prevent heart attacks?\n","\n","In the same study, the researchers also recorded the number of strokes in\n","each group:\n","\n","aspirin group (n=11037): 119 strokes; 10918 without stroke\n","placebo group (n=11034): 98 strokes; 10936 without stroke\n","\n","Scientific question #2: Does aspirin increase the risk of having a\n","stroke?\n","\n","We will start by addressing the 2nd question regarding strokes. The code\n","you generate here will then allow you to rapidly analyze the heart attack\n","data.\n","\n","**What to do:** \n","\n","Login to learning catalytics and join the session for the\n","module entitled \"ASA Bootstrap\". You will answer a series of\n","questions based on the guided programming below. Each section begins with\n","a '%%'. Read through the comments and follow the instructions provided.\n","In some cases you will be asked to answer a question, clearly indicated\n","by 'QUESTION'. In other cases, you be asked to supply missing code,\n","indicated by 'TODO'. The corresponding question in learning catalytics\n","will be indicated in parentheses (e.g. Q1). If there is no 'Q#'\n","accompanying a 'QUESTION' just type your answer into this script and\n","discuss it with your team. Once you have supplied the required code, you\n","can execute that section by mouse-clicking in that section (The block\n","will turn yellow.) and then simultaneously hitting the 'ctrl' and 'enter'\n","keys (PC) or 'command' and 'enter' keys (Mac).\n","\n","\n","**Concepts covered:**\n","1. Test for proportions: odds ratio\n","2. Comparing resampling tests with Fisher's exact test\n","3. Std. error and confidence intervals through bootstrapping\n","4. Relationship between CI and hypothesis test\n","5. Permutation test for strong test of H0.\n","6. One-tailed vs. two-tailed tests.\n","7. CI with 'bootci' and an anonymous function\n","8. Making data tables with 'table' command\n"]},{"cell_type":"code","metadata":{"id":"os-GAIZtZGK8"},"source":["# Imports\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K3BV7sU8RWo5"},"source":["# Constants: these would normally be passed as arguments to a function\n","\n","n_boot = 10000\n","my_alpha = 0.05\n","\n","# useful numbers for stroke data\n","n_rx = 11037  # total number of patients in the treatment group (ASA)\n","n_stroke_rx = 119  # number of strokes in the treatment group\n","n_ctrl = 11034  # total number of patients in the control group (placebo)\n","n_stroke_ctrl = 98  # number of strokes in the control group\n","n_total = n_rx + n_ctrl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IY8N6GqITfkz"},"source":["##  Calculate the actual ratio of rates of disease: an odds ratio\n","\n","This is defined as the ratio of 2 ratios: the numerator is the ratio of\n","the number of subjects in the treatment group who had a stroke divided by\n","the number who did not have a stroke. The denominator is the same, but\n","for the control group.\n"]},{"cell_type":"code","metadata":{"id":"o5yMfeQ0TYnr"},"source":["# TODO: calculate the odds ratio for this study\n","or_hat = ...\n","\n","print(or_hat)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hoLLEXShTlXU"},"source":["**QUESTION (Q1)**: What is your odds ratio to 4 decimal places?\n"]},{"cell_type":"markdown","metadata":{"id":"MqVJzroDUmVh"},"source":["## Create a population from which to resample:\n","\n","The general approach in bootstrapping is to resample from our *original\n","sample*. But you've been given only proportions, so you have to\n","*re-create* the raw data based on the proportions. It's alarmingly\n","simple, but you might have to think about it for a bit. (Note that we won't use the tidy format here to sync better with Matlab)\n","\n","HINT: You should be able to re-calculate your original odds ratio with this formula:\n","`( data['rx_grp'].sum() / (data['rx_grp'] == 0).sum() ) / ( data['ctrl_grp'].sum() / (data['ctrl_grp'] == 0).sum() )`"]},{"cell_type":"code","metadata":{"id":"NzP4fxsv4CVy"},"source":["n_rows = np.max([n_ctrl, n_rx])\n","\n","data = pd.DataFrame({'ctrl_grp': np.nan * np.ones((n_rows,)),\n","                     'rx_grp': np.nan * np.ones((n_rows, )) })\n","\n","# TODO: recreate the raw data\n","... # your code here!!\n","\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vX-cbCgrw5BP"},"source":["( data['rx_grp'].sum() / (data['rx_grp'] == 0).sum() ) / ( data['ctrl_grp'].sum() / (data['ctrl_grp'] == 0).sum() )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zdhIAv7E4a6D"},"source":["Note that we have some NaNs to make these columns the same size. To grab the non-Nan data, which you'll need to do below, use `data['ctrl_grp'].dropna()`"]},{"cell_type":"markdown","metadata":{"id":"oTIaiqb5ba8g"},"source":["## Generate bootstrap replicates of the odds ratio\n"]},{"cell_type":"code","metadata":{"id":"H2MylrnG4WXl"},"source":["# holds each bootstrap calc. of the odds ratio\n","or_bootstrap = pd.DataFrame({'or_star': np.zeros((n_boot,))}) \n","\n","# set random seed\n","np.random.seed(123)\n","\n","for k in range(n_boot):\n","\n","    # TODO: Re-sample from each group WITH REPLACEMENT to create two new\n","    # samples: rx_star and ctrl_star. Then use these two bootstrap samples to\n","    # calculate an odds ratio and store it in or_bootstrap['or_star']\n","    rx_star = ...\n","    ctrl_star = ...\n","    or_bootstrap.loc[k, 'or_star'] = ...  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"218wwd1fjC_t"},"source":["## Make a histogram of our bootstrap replicates of OR\n"]},{"cell_type":"code","metadata":{"id":"Hu1seBHk28dq"},"source":["fig, ax = plt.subplots(1, 1)\n","\n","sns.histplot(data = or_bootstrap, x = 'or_star', ax = ax)\n","\n","ax.plot([or_hat, or_hat], ax.get_ylim(), 'lime', lw = 2)\n","ax.set(xlabel = 'OR^*',\n","       ylabel = '#',\n","       title = 'Distribution of bootstrapped odds ratios');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gx_4ZTkDdrY6"},"source":["## Calculate the standard error and the confidence intervals\n"]},{"cell_type":"code","metadata":{"id":"kbesRPmT5L3G"},"source":["# TODO: Compute the bootstrap estimate of the standard error of the odds ratio\n","sem_boot = or_bootstrap['or_star'].std()\n","\n","sem_boot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u70xYn0Bd8IK"},"source":["**QUESTION (Q2)**: What is bootstrap estimate of the standard error of the odds ratio?"]},{"cell_type":"code","metadata":{"id":"LBBnh-Bd5REB"},"source":["# Use the percentile method to determine the 95% confidence interval.\n","\n","... # !! more code here\n","\n","conf_interval = ...\n","\n","print(conf_interval)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DtpG3fJkezOf"},"source":["**QUESTION (Q3)**: What is the 95% CI based on your bootstrap distribution?\n","\n","**QUESTION (Q4)**: What is the null value of the odds ratio?\n","\n","**QUESTION (Q5)**: How can we use the known null value of the odds ratio to\n","perform a hypothesis test?\n","\n","**QUESTION (Q6)**: Can we reject H0 at an alpha of 0.05?\n"]},{"cell_type":"markdown","metadata":{"id":"3TlwGD3-hhbF"},"source":["## Plot CIs on histogram\n"]},{"cell_type":"code","metadata":{"id":"Rso8jYAs4Czy"},"source":["fig, ax = plt.subplots(1, 1)\n","sns.histplot(data = or_bootstrap, x = 'or_star');\n","\n","ylims = ax.get_ylim()\n","\n","ax.plot([or_hat, or_hat], ylims, 'lime', lw = 2, label = 'or_hat')\n","\n","# Add CIs\n","ax.plot([conf_interval[0], conf_interval[0]], ylims, 'r', label = '95% CI')\n","ax.plot([conf_interval[1], conf_interval[1]], ylims, 'r')\n","\n","ax.legend()\n","\n","ax.set(xlabel = 'OR^*',\n","       ylabel = '#',\n","       title = 'Distribution of bootstrapped odds ratios');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9RgOc8ZwkjMr"},"source":["## Perform an explicit hypothesis test by modeling our OR under H0\n","\n","In this case, we will use a permutation test, where we resample WITHOUT\n","replacement. The logic is that we are essentially randomly assigning each\n","patient to the treatment or control group, then recalculating our odds\n","ratio. Here, we are testing the most extreme version of H0, which is that\n","the two distributions are the SAME.\n","\n"]},{"cell_type":"code","metadata":{"id":"-bQaUk9x5tkv"},"source":["# TODO: Perform resampling as though the patients all belonged to the\n","# same group (called H0_data), shuffle this data, then arbitraily assign\n","# each patient to the treatment or control group and compute the odd ratio. \n","# Store each bootstrapped odds ratio in orPerm\n","\n","# Pool all the data:\n","H0_data = pd.concat([data['rx_grp'].dropna(), data['ctrl_grp'].dropna()])\n","\n","# Place to store our results:\n","or_bootstrap['or_perm'] = np.zeros((n_boot,))\n","\n","# Set random seed\n","np.random.seed(123)\n","\n","# Loop over bootstraps\n","for k in range(n_boot):\n","\n","    # Shuffle and assign to rx_star and ctrl_star (ALL values are used!)\n","    ... # !! your code here\n","    or_bootstrap.loc[k, 'or_perm'] = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pM9j-iK7n8_I"},"source":["## Plot the distrubtion of permuted ORs\n"]},{"cell_type":"code","metadata":{"id":"RFttsris7-JS"},"source":["fig, ax = plt.subplots(1, 1)\n","sns.histplot(data = or_bootstrap, x = 'or_perm');\n","\n","ylims = ax.get_ylim()\n","\n","ax.plot([or_hat, or_hat], ylims, 'lime', lw = 2, label = 'or_hat')\n","\n","ax.legend()\n","\n","ax.set(xlabel = 'Permuted ORs',\n","       ylabel = '#',\n","       title = 'Distribution of ORs under H0');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YJfWoCONiFjU"},"source":["## Calculate a 1-tailed p-value"]},{"cell_type":"code","metadata":{"id":"QiqskQA3hwUI"},"source":["# TODO: Calculate a one-tailed p-value based on your permuted samples (i.e.\n","# or_perm) and store it in a variable called 'p_val_1t'\n","p_val_1t = ...\n","\n","p_val_1t"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RdeeRXY4iTs-"},"source":["**QUESTION (Q7)**: What is our one-tailed p-value for the odds ratio?\n"]},{"cell_type":"markdown","metadata":{"id":"NhCHL_nUi4A_"},"source":["## Calculate a 2-tailed p-value"]},{"cell_type":"code","metadata":{"id":"AjkMh6c3iUji"},"source":["# TODO: Calculate a two-tailed p-value based on your permuted samples (i.e.\n","# or_perm) and store it in a variable called 'p_val_2t'\n","p_val_2t = ...\n","\n","p_val_2t"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ksL521ojYXJ"},"source":["**QUESTION (Q8)**: What is our two-tailed p-value for the odds ratio?\n","\n","Philosophical interlude: The difference in implementation between\n","2-tailed and 1-tailed p-value is pretty clear. The philosophical\n","difference, somewhat less. If you accidentally coded a 2-tailed test and\n","get a p value of, say,0.06, and then remember \"Oh! A 1-tailed test was\n","actually more appropriate!\" (and it really is in that instance, not for a\n","\"p-hacky\" reason) and obtain p ~ 0.03, there's a sudden shift in\n","perspective on the data. But it's the same data, and you're performing\n","more or less the same analysis. Does this seem even remotely reasonable?\n","This very subtle distinction would have a pretty heavy impact on a\n","statistics-naïve researcher. It can be helpful to think about edge cases\n","like this, where our arbitrary thresholding statistical procedure leads\n","to binarization of the same data into two categories which are\n","interpreted in very different ways, and how we should consider data of\n","this variety. Is it helpful to construct a new categorization, e.g.\n","\"statistically significant (p small),\" \"unlikely to produce statistical\n","significance (p biggish)\" and \"of uncertain relationship (p kinda\n","small?)\" or does that just move the problem?\n","\n","See my article: https://www.eneuro.org/content/6/6/ENEURO.0456-19.2019"]},{"cell_type":"markdown","metadata":{"id":"-DVIiKAmmvq5"},"source":["## Compare with the Fisher Exact Test for Stroke data\n"]},{"cell_type":"code","metadata":{"id":"dwximEsl7k_f"},"source":["import scipy.stats\n","\n","table = np.array([[n_stroke_rx, n_rx - n_stroke_rx], \n","                  [n_stroke_ctrl, n_ctrl - n_stroke_ctrl]])\n","\n","\n","# TODO: Calculate a 2-tailed p-value and 95% confidence interval using Fisher's Exact Test\n","... # your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mc7V0THL-Rqi"},"source":["This function doesn't return the confidence interval, unlike the Matlab version, so I implemented it myself below. See the equations [here](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717_ComparingFrequencies/PH717_ComparingFrequencies8.html).\n"]},{"cell_type":"code","metadata":{"id":"B2yS6Z9A-Ocz"},"source":["# Compute lower bound of 95% confidence interval\n","\n","# Compute the standard error of odds ratio\n","se = np.sqrt( 1 / table[0, 0] + 1 / table[0, 1] + 1 / table[1, 0] + 1 / table[1, 1])\n","\n","# Get the confidence interval\n","norm_inv = scipy.stats.norm.ppf((1 - my_alpha / 2))\n","conf_interval_fisher = [odds_ratio*np.exp(-norm_inv*se), odds_ratio*np.exp(norm_inv*se)]\n","\n","print(conf_interval_fisher)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sr7RkJ_lnWjY"},"source":["**QUESTION (Q9)**: What p-value does Fisher's Exact Test give?\n","\n","**QUESTION (Q10)**: What is the lower bound of the 95% CI from Fisher's Exact\n","Test?\n","\n","Be sure to compare this with your values from the bootstrap!\n","\n","**QUESTION (Q11)**: Save your final figure for the stroke data as a jpeg and\n","upload it to the LC site.\n"]},{"cell_type":"markdown","metadata":{"id":"BjZzGuO7nrXs"},"source":["## Repeat calculations for the heart attack data"]},{"cell_type":"code","metadata":{"id":"31Uqdu5XCG1A"},"source":["# Useful numbers for heart attack data\n","n_rx = 11037  # number of patients in the treatment group (ASA)\n","n_MI_rx = 104  # number of heart attacks (= MIs) in the treatment group\n","n_ctrl = 11034  # number of patients in the control group (placebo)\n","n_MI_ctrl = 189  # number of MIs in the control group\n","\n","# Generate the raw data\n","n_rows = np.max([n_ctrl, n_rx])\n","\n","data = pd.DataFrame({'ctrl_grp': np.nan * np.ones((n_rows,)),\n","                     'rx_grp': np.nan * np.ones((n_rows, )) })\n","\n","... # your code here\n","\n","data.head()\n","\n","# Odds ratio for MI data\n","or_hat = ...\n","\n","print(or_hat)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SW2Lc51drAXS"},"source":["**QUESTION (Q12)**: What is the odds ratio, `or_hat`, for the heart attack data?\n","\n","TODO: Repeat the above analysis for the MI data. If you wrote\n","everything in terms of `rx_grp` and `ctrl_grp`, then once you've generated\n","the corresponding raw values for the MI data, you should be able to just\n","re-run cells below the first dataframe creation/odds ratio computation without further edits to your code.\n","\n","**QUESTION (Q13)**: What is the bootstrap estimate of the 95% CI of the odds\n","ratio for the heart attack data?\n","\n","**QUESTION (Q14)**: Can we reject H0 at an alpha of 0.05 for the heart attack data?\n","\n","**QUESTION (Q15)**: Based on the permutation test, what is your 1-sided\n","p-value for the heart attack data?\n","\n","Be sure to compare the confidence intervals that you obtain\n","through bootstrapping to those obtained with Fisher's Exact Test."]}]}
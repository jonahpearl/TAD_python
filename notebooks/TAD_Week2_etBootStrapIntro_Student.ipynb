{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TAD_Week2_etBootStrapIntro_Student.ipynb","provenance":[{"file_id":"1AZ6AigkLtbO4OLzoNRi40gXYv5rHHyp3","timestamp":1629079431806}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kB_ZxfYqxEs-"},"source":["# Bootstrapping SE's and CI's with Grad School Data"]},{"cell_type":"markdown","metadata":{"id":"Q6MPwY-DxNE8"},"source":["**Instructions:**\n","\n","The goal of this exercise is to become familiar with the technique of\n","bootstrapping and appreciate how it can be used to estimate the precision\n","of statistics through resampling data to generate standard errors and\n","confidence intervals that may otherwise be difficult to compute directly.\n","\n","**What to do:**\n","\n","Login to learning catalytics and join the session for the\n","module entitled \"Grad School Correlations\". You will answer a series of\n","questions based on the guided programming below. Each section begins with\n","a '%%'. Read through the comments and follow the instructions provided.\n","In some cases you will be asked to answer a question, clearly indicated\n","by 'QUESTION'. In other cases, you be asked to supply missing code,\n","indicated by 'TODO'. The corresponding question in learning catalytics\n","will be indicated in parentheses (e.g. Q1). If there is no 'Q#'\n","accompanying a 'QUESTION' just type your answer into this script and\n","discuss it with your team. \n","\n","Original source of exercise:\n","Efron, B. & Tibshirani Robert, J. (1993) An introduction to the\n","bootstrap. Chapman & Hall, London, see Table 3.2 on p. 21\n","\n","RTB wrote it 07 July 2019 (Kinsale, Ireland; Cork Distance Week,\n","\"Champion of Champions\" day), ERBB translated to Python on 04 August, 2021\n","\n","\n","**Concepts covered:**\n","1. Standard error of the mean calculated 3 ways:\n","      a) formula, b) population sampling, c) bootstrap sampling\n","2. Calculating correlation coefficients with 'corr'\n","3. Bootstrapping standard errors with the built-in 'bootstrp' function\n","4. Bootstrapping confidence intervals with the built-in 'bootci' function\n","5. Parametric bootstrap by sampling from a bivariate normal distribution\n","\n","The data here are GRE (quant) and GPA (science) scores from a census of\n","82 graduate programs in neuroscience. We also have a random sample of 15\n","schools from this census as well. Note that these data were collected\n","prior to August of 2011, so the GRE scores were scaled from 200 to 800.\n"]},{"cell_type":"code","metadata":{"id":"0mO6IbNwyFBj"},"source":["import pandas as pd\n","import numpy as np\n","\n","import seaborn as sns\n","sns.set(rc={'figure.figsize':(10, 5)})\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9AMQxUV8w_Bp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631141466092,"user_tz":240,"elapsed":854,"user":{"displayName":"Ella Batty","photoUrl":"","userId":"17939168843900203228"}},"outputId":"ce647950-6c85-40a9-b2f7-f159a727d3ca"},"source":["# Read in the data\n","ds82 = pd.read_excel('https://github.com/rickborn/TAD/blob/master/Unit%20%232%20Bootstrap%201/Grad_School_82.xlsx?raw=true') # All graduate programs (*census*)\n","ds15 = pd.read_excel('https://github.com/rickborn/TAD/blob/master/Unit%20%232%20Bootstrap%201/Grad_School_15.xlsx?raw=true') # Random sample of 15\n","\n","# Define a few constants\n","n_boot = 10000\n","n_samp = len(ds15.GRE)\n","n_census = len(ds82.GRE)\n","\n","# Look at the original excel spreadsheet for one of the files and compare\n","# it to the variable that 'pd.read_excel' created in Python. \n","ds15.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['SchoolID', 'GRE', 'GPA'], dtype='object')"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"YYoQ1FEx0QvN"},"source":["# Plot GPA and GRE scores\n","\n","fig, ax = plt.subplots(1, 1, figsize = (10, 5))\n","\n","# Set axis limits\n","ax.set(xlim = [450, 750])\n","\n","# Plot census scatter plot and least-squares line\n","sns.regplot(data = ds82, x = 'GRE', y = 'GPA', ax = ax, truncate = False, ci = None,\n","            color = 'k', marker = '+',\n","            scatter_kws={\"s\": 100}, \n","            label = 'Census')\n","\n","# Plot sample scatter plot and least-squares line\n","sns.regplot(data = ds15, x = 'GRE', y = 'GPA', ax = ax, truncate = False, ci = None,\n","            color = 'r', marker = 'o', \n","            scatter_kws={\"s\": 100, \"facecolor\":'none', \"edgecolor\":'r'}, \n","            label = 'Sample')\n","\n","# Add legend\n","ax.legend()\n","\n","# Set axis labels\n","ax.set(xlabel = 'GRE Score (quant)', ylabel = 'GPA (science)');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WX-nnkhc6FE8"},"source":["## Mean GRE score & standard error (SE)\n","We start with something that is easy to compute directly. The reason we\n","can do this is that, thanks to the Central Limit Theorem, we KNOW that\n","the sampling distribution of the mean, regardless of the distribution of\n","the original data from which the mean was calculated, will be normally\n","distributed. Furthermore, we know that the standard deviation of the\n","sampling distribution for the mean will be equal to the sample standard\n","deviation divided by the square-root of the number of samples. This is\n","the standard error of the mean.\n","\n","NOTE: There are two standard deviations at play here. The first is the\n","standard deviation that we calculate from our sample--this is the sample\n","standard deviation. But, in the next sections, we will be explicitly\n","calculating the \"sampling distribution of the mean,\" which is the\n","distribution of mean values we would get if we re-took our sample of 15\n","many different times and calculated a new sample mean each time. The\n","standard deviation of the sampling distribution of the mean is, by\n","definition, the standard error. In fact, and this is very important to\n","just flat out memorize until practice makes it intuitive: THE STANDARD\n","ERROR OF ANY STATISTIC IS THE STANDARD DEVIATION OF THE SAMPLING\n","DISTRIBUTION OF THAT STATISTIC. The mean is a special case where we can\n","use a handy-dandy formula to calculate the standard deviation of the\n","sampling distribution (i.e. the standard error of the mean) based on the\n","standard deviation of our single sample.\n","\n","*Python note*: Pandas and matlab both divide by n - 1 when they compute standard deviation. In numpy, the std is computed by dividing by n, unless you change the `ddof` (degrees of freedom) argument. Use pandas to sync with Matlab.\n"]},{"cell_type":"code","metadata":{"id":"Wzy_AiuA5hXW"},"source":["# TODO: Calculate the mean GRE score for your sample and its standard error (SE) \n","\n","mean_GRE = ...\n","sem_GRE = ...\n","\n","sem_GRE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"afSZZVt_6U6T"},"source":["\n","**QUESTION (Q1)**: What is the value of semGRE to 2 decimal places?\n"]},{"cell_type":"markdown","metadata":{"id":"ZDRn4cGgkAX3"},"source":["# Bootstrapping"]},{"cell_type":"markdown","metadata":{"id":"_jxAbDx8s6fW"},"source":["## \"True\" standard error by sampling from the population\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"JdjEr3MH6x5F"},"source":["all_means = pd.Series(np.zeros(n_boot,))\n","\n","np.random.seed(123) # for consistency across class; You would not normally do this.\n","for k in range(n_boot):\n","\n","    # TODO: Draw n_boot samples of size 15 (n_samp) from the CENSUS of 82, each time \n","    # calculating the sample mean. Save each mean in 'all_means'\n","    all_means[k] = ...\n","\n","# Look at the sampling distribution of the mean\n","ax = sns.histplot(data = all_means, bins = 10)\n","ax.set(xlabel = 'mean GRE score', ylabel = '# of samples of size 15',\n","       title = 'Distribution of means, sampling from census');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9ZVbJFIwgyF"},"source":["# TODO: calculate the standard error of the mean from this sample:\n","sem_GRE_samp = ...\n","\n","sem_GRE_samp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VcSMxd1Cv048"},"source":["**QUESTION** (Q2): What is the value of `sem_GRE_samp` to 2 decimal places? "]},{"cell_type":"markdown","metadata":{"id":"Q6-B1eoKwA66"},"source":["## Bootstrap standard error by sampling from the sample\n","\n","Calculate another SEM as you did above, but now, instead of drawing your samples from the CENSUS, you will draw your samples from the sample.\n","You do this by sampling WITH REPLACEMENT from your original actual sample of the 15 graduate schools. This is the essence of the bootstrap!\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"IPvsyV24vQN3"},"source":["all_means_bootstrap = pd.Series(np.zeros(n_boot,))\n","\n","np.random.seed(123) \n","for k in range(n_boot):\n","\n","    # TODO: sample with replacement from the sample and get mean\n","    all_means_bootstrap[k] = ...\n","\n","# Visualize the sampling distribution of the mean\n","fig, axes = plt.subplots(2, 1, figsize = (10, 7))\n","bin_edges = np.histogram_bin_edges(all_means_bootstrap)\n","\n","sns.histplot(data = all_means, bins = bin_edges, ax = axes[0])\n","axes[0].set(xlabel = 'mean GRE score', ylabel = '# of samples of size 15',\n","       title = 'Distribution of means, sampling from census', ylim = [0, 3100]);\n","\n","sns.histplot(data = all_means_bootstrap, bins = bin_edges, ax = axes[1])\n","axes[1].set(xlabel = 'mean GRE score', ylabel = '# of samples of size 15',\n","       title = 'Distribution of means, re-sampling from the sample', ylim = [0, 3100]);\n","\n","plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2Z9XUzNPyXk"},"source":["# TODO: calculate the standard error of the mean from the bootstrap \n","#      sampling distribution of the means\n","sem_GRE_boot = ...\n","\n","sem_GRE_boot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lyFFIbbPxR0F"},"source":["**QUESTION** (Q3): What is the value of `sem_GRE_boot` to 2 decimal places? \n"]},{"cell_type":"markdown","metadata":{"id":"Cn4dRCoExWUT"},"source":["**QUESTION** (Q4): What is the error (in %) of the bootstrap estimate w/r/t that of the formula? Calculate in next cell. Round to the nearest whole number in %.\n","\n"]},{"cell_type":"code","metadata":{"id":"OoS6BjN3xajh"},"source":["# TODO: Compare your bootstrap estimate of the SE with that from the formula\n","percent_error = ...\n","\n","percent_error"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lIvcxVoxuk2"},"source":["## Correlation of GRE and GPA in census and sample"]},{"cell_type":"code","metadata":{"id":"Q7Zb06Viwhon"},"source":["# TODO: Use pandas dataframe method `corr` to calculate correlation \n","#       coefficients of both the census and sample\n","\n","rho_hat_82 = ...\n","rho_hat_15 = ...\n","\n","print(rho_hat_82)\n","print(rho_hat_15)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TgyGkLj5x1G_"},"source":["**QUESTION (Q5)**: What is a correlation coefficient?\n","\n","**QUESTION (Q6)**: What is the correlation coefficient for the census? \n","\n","**QUESTION (Q7)**: Based on the correlation coefficient and the graph, would you guess GRE score and GPA are correlated?\n"]},{"cell_type":"markdown","metadata":{"id":"9kvUWZUOy6UE"},"source":["## Standard error for the correlation coefficient\n","\n"]},{"cell_type":"code","metadata":{"id":"sFyl8WugZZbh"},"source":["# Set up a pandas dataframe for various ways of estimating the standard error of \n","#  the correlation coefficient\n","\n","rhos = pd.DataFrame({\n","       'bs_rhos': np.zeros(n_boot,),\n","       'all_rhos_TS': np.zeros(n_boot,)\n","    })"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PTzj31X1aq_F"},"source":["Unlike for the mean, there is no handy, dandy formula for the standard error of a correlation coefficient. This is where the bootstrap comes in!\n","\n","Get a bootstrap sample of correlation coefficients the old fashioned way, using a 'for' loop. Store in our pandas dataframe `rhos` in the column `bs_rhos`."]},{"cell_type":"code","metadata":{"id":"3o4cYpZqx5IX"},"source":["np.random.seed(123) # for reproducibility\n","\n","for k in range(n_boot):\n","\n","    # TODO: Randomly sample n_samp rows from ds15 with replacement\n","    sampled_rows = ...\n","    \n","    # TODO: Compute the correlation of GRE score and GPA for this sample\n","    rhos['bs_rhos'][k] = ...\n","\n","ax = sns.histplot(rhos['bs_rhos'])\n","ax.set(xlabel = 'Correlation coefficient', ylabel = 'Probability');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ba51UEIpXVbV"},"source":["# Compute standard error of our correlation coefficient\n","se_rho_boot = ...\n","\n","se_rho_boot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jt4DvlubzBhD"},"source":["**QUESTION (Q8)**: What is the value of `se_rho_boot` (referred to as `se_rho_boot_FL` in learning catalytics) to 4 decimal places?\n","\n"]},{"cell_type":"code","metadata":{"id":"Q5QB1kpuXPk5"},"source":["# Compute mean of distribution\n","mean_rho_boot = ...\n","\n","mean_rho_boot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SoxTv3cPX439"},"source":["**QUESTION (Q9)**: What is the mean of this distribution to 2 decimal places?\n"]},{"cell_type":"markdown","metadata":{"id":"1jSaNIn9X7Ck"},"source":["Q10/Q11/Q12 are specific to Matlab"]},{"cell_type":"markdown","metadata":{"id":"eMJCBxtt2NO9"},"source":["## Sample from census\n","\n","As we did above for the mean, we can take advantage of the fact that we\n","have data for the complete population (i.e. census), and see how our\n","estimate of rho is distributed when we repeatedly sample from the\n","population. That is, instead of re-sampling our sample of 15 with\n","replacement, we sample the 'population' of 82 graduate schools with\n","replacement.\n","\n","Store in our pandas dataframe `rhos` in the column `all_rhos_TS`."]},{"cell_type":"code","metadata":{"id":"bIUzE5gZzDbS"},"source":["np.random.seed(123)  # for reproducibility\n","for k in range(n_boot):\n","\n","    # TODO: Randomly sample n_samp rows from ds82 with replacement\n","    sampled_rows = ...\n","    \n","    # Compute the correlation of GRE score and GPA for this sample\n","    rhos['all_rhos_TS'][k] = ...\n","\n","# Visualize\n","ax = sns.histplot(rhos)\n","plt.legend(['Census', 'Bootstrap'])\n","ax.set(xlabel = 'Correlation coefficient', ylabel = 'Probability');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0XWIXUNSVu8E"},"source":["**QUESTION (Q13)**: How does this distribution compare to the bootstrapped resampling of 15 schools? Consider the general skew, spread, location (i.e. mean,median) of the distributions."]},{"cell_type":"markdown","metadata":{"id":"tI7hk7_wW5KN"},"source":["**Question (Q14)**: Compute the standard error of the correlation coefficient for the samples bootstrapped from the population."]},{"cell_type":"code","metadata":{"id":"z4oNecE22pAU"},"source":["# TODO: Compute the standard error of the correlation coefficient for the samples \n","# bootstrapped from the population.\n","se_rho_boot_TS = ...\n","\n","se_rho_boot_TS"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6m_7RBoeXBcm"},"source":["## The 'parametric bootstrap' (p. 53 of E&T)\n","\n","\"Instead of sampling with replacement from the data, we draw B samples of\n","size n from the parametric estimate of the population.\"\n","\n","The parametric bootstrap differs from the traditional bootstrap in that\n","we fit a model to the data and then draw random numbers from this fitted\n","model, rather than resampling the data itself. Why might one want to do\n","this? Well, in rare instances when one wants to bootstrap the SE for some\n","sample 'outlier', such as the 'min' or 'max', the data-driven bootstrap\n","will fail. (Try this and see for yourself what is going on.) In such\n","cases, the parametric bootstrap gets it right.\n","\n","In this case, we will assume that the population has a bivariate normal\n","distribution, with means `mu_hat` and a covariance matrix of `cov_hat`.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"lVvx1xWGWpYU"},"source":["mu_hat = ds15[['GRE', 'GPA']].mean()\n","cov_hat = ds15[['GRE', 'GPA']].cov()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6TlUo3n_YScC"},"source":["Using what we learned from bootstrapping, create a 'for' loop that uses the `np.random.multivariate_normal` function to draw n_boot samples of size `n_samp` from a bivariate normal distribution with mean `mu_hat` and covariance `cov_hat`. Compute the correlation coefficient for each sample and store in the column called `pbs_rhos` of our pandas dataframe `rhos`, which is initialized below. "]},{"cell_type":"code","metadata":{"id":"CV34bzTrXkZe"},"source":["rhos['pbs_rhos'] = np.zeros((n_boot,));\n","\n","np.random.seed(123)\n","for k in range(n_boot):\n","\n","    # Draw samples from normal distribution\n","    R = ...\n","\n","    # Compute correlation coefficient (use np.corrcoef)\n","    rhos['pbs_rhos'][k] = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AmYg5Cz5aBJD"},"source":["**QUESTION (Q15)**: What is the standard error of the correlation coefficient as determined by parametric bootstrapping? Compute in code below"]},{"cell_type":"code","metadata":{"id":"Na8FTZFoXlC8"},"source":["# TODO: get standard error of correlation coefficient from parametric bootstrapping\n","se_rho_PBS = ...\n","\n","se_rho_PBS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8L7ffhrEeZ6-"},"source":["# Visualize\n","ax = sns.histplot(rhos)\n","plt.legend(['Parametric', 'Census', 'Bootstrap'])\n","ax.set(xlabel = 'Correlation coefficient', ylabel = 'Probability');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDsdfyq4fOqp"},"source":["print(se_rho_boot)\n","print(se_rho_boot_TS)\n","print(se_rho_PBS)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RUrUS4GybZUB"},"source":["**QUESTION (Q16)**: How does the SE of the correlation coefficient compare to our other bootstrapping strategies? If it's different, why do you think this may be so?"]},{"cell_type":"markdown","metadata":{"id":"qNHNSuczbuDA"},"source":["Let's look at a side-by-side view of our histograms\n"]},{"cell_type":"code","metadata":{"id":"P8tDMH5Dgjyv"},"source":["fig, ax = plt.subplots(1, 1, figsize = (10, 5))\n","ax.hist(np.array(rhos), bins = 25);\n","\n","ax.set(xlim = [0, 1], xlabel = 'Correlation coefficient', ylabel = '# of bootstrap replicates',\n","       title = 'Distribution of rho values')\n","plt.legend(['Bootstrap','Census','Parametric']);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Liy3ZKxyfR50"},"source":["# Confidence intervals\n","\n","We have used several different strategies to create sampling\n","distributions:\n","  1. Repeated sampling from the entire population.\n","  2. Repeated re-sampling from our original sample (bootstrap)\n","  3. Repeated sampling from a population defined by parameters derived\n","     from our original sample (parametric bootstrap)\n","\n","But in each case, we have generated an estimate of the sampling\n","distribution for a given statistic. Thus far, we have used these\n","distributions to generate a single estimate of precision: the standard\n","error. However, we can use these same distributions to calculate other\n","measures of precision, such as confidence intervals. After all, under\n","normal assumptions, a standard error is a kind of confidence interval,\n","since we expect about 68% of the distribution to be within +/- s.d. That\n","is, for example, the SEM can be thought of as defining a 68% CI for our\n","estimate of the mean. But we can go further.\n"]},{"cell_type":"markdown","metadata":{"id":"kA249ISHjs8x"},"source":["## CI by asymptotic normal distribution theory\n","\n","Since the std. error is the 68% CI, we can get any other CI by just calculating the appropriate number of standard deviates from the normal distribution. Let's use our distribution of `rhos[bs_rhos]`, calculated above.\n","\n","Below, we show the mean of the distribution with the vertical black dashed line."]},{"cell_type":"code","metadata":{"id":"NJIaqDf_cySA"},"source":["# Plot of distribution of bootstrapped correlation coefficients\n","ax = sns.histplot(rhos['bs_rhos'], bins = 100)\n","_, y_max = ax.get_ylim()\n","ax.plot([rhos['bs_rhos'].mean(), rhos['bs_rhos'].mean()], [0, y_max], '--k')\n","ax.set(xlabel = 'Correlation coefficient', ylabel = 'Probability',\n","       title = 'Distribution of rho values: boostrap',\n","       xlim = [0.15, 1.1]);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZb_ZqjZlFll"},"source":["# This is our mean correlation\n","mean_rho_boot = rhos['bs_rhos'].mean()\n","\n","# This is our 68% CI\n","se_rho_boot = rhos['bs_rhos'].std()\n","\n","# Set alpha for a 95% CI\n","my_alpha = 0.05"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iz4zI4N7msdg"},"source":["You probably remember that a 95% CI is +/- 1.96 standard deviates. So we\n","could calculate our CI as `mean_rho_boot` +/- 1.96*`se_rho_boot`. But say we\n","wanted to be able to calculate any arbitrary confidence interval. For a\n","99% CI, we would set `my_alpha` to 0.01.\n"]},{"cell_type":"code","metadata":{"id":"CjqXP01jltCD"},"source":["# TODO: Write a line of code that will convert a desired CI, \n","#       expressed as my_alpha to the appropriate number of standard deviates. \n","#       Use `norm` from scipy.stats, imported below\n","from scipy.stats import norm\n","num_std_deviates = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G22s-OFkwJve"},"source":["**QUESTION (Q17)**: What is `num_std_deviates` for `my_alpha` = 0.001?"]},{"cell_type":"code","metadata":{"id":"uqEaEA3UuoTf"},"source":["# TODO: Calculate the lower and upper bounds for the 95% CI\n","rho95_CI_low = ...\n","rho95_CI_hi = ...\n","\n","print(rho95_CI_low)\n","print(rho95_CI_hi)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SQmfUlHqwmNp"},"source":["**QUESTION (Q18)**: What is the value of `rho95_CI_hi`?\n","\n","**QUESTION (Q19)**: Does this value make sense? Why or why not?\n"]},{"cell_type":"code","metadata":{"id":"ZMemJk-ioB40"},"source":["# Plot of distribution of bootstrapped correlation coefficients\n","ax = sns.histplot(rhos['bs_rhos'], bins = 100)\n","_, y_max = ax.get_ylim()\n","ax.plot([rhos['bs_rhos'].mean(), rhos['bs_rhos'].mean()], [0, y_max], '--k')\n","\n","# TODO: Draw lines for the 95%CI on our histogram in red \n","ax.plot(...) \n","ax.plot(...) \n","\n","ax.set(xlabel = 'Correlation coefficient', ylabel = 'Probability',\n","       title = 'Distribution of rho values: boostrap',\n","       xlim = [0.15, 1.1]);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KQef0A27zTjt"},"source":["##  CI by percentile method\n","\n","In this case, we generated 10,000 samples, so a more intuitive, brute-force way to calculate the 95% CI is just to sort our bootstrap replicates and then find the values corresponding to 250th and the 9750th index in the sorted array.\n"]},{"cell_type":"code","metadata":{"id":"ikQHd5ydzQ5N"},"source":["# Sort our bootstrap replicates\n","bs_rhos_sorted = rhos['bs_rhos'].sort_values()\n","\n","# TODO: find indices corresponding to lower and upper bounds\n","idx_lo = ...   # index corresponding to lower bound\n","idx_hi = ...  # index corresponding to upper bound\n","\n","# Get high and low bounds using percentiles (remember to use iloc if a pandas format)\n","rho95_CI_percentile_low = bs_rhos_sorted.iloc[int(idx_lo)]\n","rho95_CI_percentile_hi = bs_rhos_sorted.iloc[int(idx_hi)]\n","\n","print(rho95_CI_percentile_low)\n","print(rho95_CI_percentile_hi)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i19Hqlr-0L8i"},"source":["**QUESTION (Q20)**: What is the lower bound of the 95% CI?\n"]},{"cell_type":"code","metadata":{"id":"Ku_OOaqurbXf"},"source":["# Plot of distribution of bootstrapped correlation coefficients\n","ax = sns.histplot(rhos['bs_rhos'], bins = 100)\n","_, y_max = ax.get_ylim()\n","ax.plot([rhos['bs_rhos'].mean(), rhos['bs_rhos'].mean()], [0, y_max], '--k')\n","\n","ax.plot([rho95_CI_low, rho95_CI_low], [0, y_max], '-r', label = 'NI. approx') \n","ax.plot([rho95_CI_hi, rho95_CI_hi], [0, y_max], '-r') \n","\n","# TODO: Draw lines for the 95%CI on our histogram in green \n","ax.plot(..., label = 'Percentile') \n","ax.plot(...) \n","\n","plt.legend()\n","ax.set(xlabel = 'Correlation coefficient', ylabel = 'Probability',\n","       title = 'Distribution of rho values: boostrap',\n","       xlim = [0.15, 1.1]);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E0rUEKE-sNYA"},"source":["Question 21 is specific to Matlab"]},{"cell_type":"markdown","metadata":{"id":"bOSTmn_Q1Slm"},"source":["**QUESTION (Q22)**: Think about this confidence interval and your earlier guess about whether GRE score and GPA are correlated. How can you use this to generate a hypothesis test? (i.e. Can we say that GRE and GPA are significantly correlated at p < 0.05?)\n","\n","**QUESTION (Q23)**: Today we've explored bootstrapping as a way to estimate standard errors and confidence intervals for means and correlation coefficients. Which of these measures are the most robust across our different ways of bootstrapping and estimating? Which are more sensitive to the method we chose?\n","\n"]}]}
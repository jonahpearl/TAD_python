{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9c52cd",
   "metadata": {},
   "source": [
    "# TAD Week 6: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d597d06",
   "metadata": {},
   "source": [
    "To include in the mini-lecture\n",
    "* geometric description of multi-d data\n",
    "* intuitive explanation of PCA\n",
    "* mathematical equation for PCA reconstruction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61885dcf",
   "metadata": {},
   "source": [
    "Today is a bit of a change from the previous weeks. Instead of focusing on statistical tests or models, we will focus instead on another important technique in data analysis: dimensionality reduction. \n",
    "\n",
    "As you saw in today's mini-lecture, principal component analysis (PCA) is a powerful tool for visualizing your data in a low-dimensional space for two reasons: it is guaranteed to capture the axes of maximum variance in your data (i.e., it is optimal and objective), and it is a linear transform (i.e. it is easy to compute and understand). UMAP is also a powerful tool, but for very different reasons: it attempts to find some low-dimensional sub-space along which your data are scattered, and to reduce that sub-space to a few dimensions while preserving the relationship of the original data. UMAP is neither optimal nor objective, opting instead for flexibility -- as we will see, this has its pros and cons.\n",
    "\n",
    "To illustrate these basic properties of PCA and UMAP, we start with MNIST, a classic machine learning dataset. Then we do a deep dive into UMAP with some scRNA-seq data, looking at its dependence on key parameters, some of its failure modes, and whether or not it really does what it claims to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a976d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import umap.plot\n",
    "from sklearn.datasets import fetch_openml\n",
    "from itertools import repeat\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy import stats\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362c5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for interactive UMAP plotting\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
    "from bokeh.palettes import Spectral10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "def plot_MNIST_sample(X):\n",
    "    \"\"\"\n",
    "    Plots 9 images in the MNIST dataset.\n",
    "    Credit: https://compneuro.neuromatch.io/tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial3.html\n",
    "    \n",
    "    Args:\n",
    "     X (numpy array of floats) : Data matrix each column corresponds to a\n",
    "                                 different random variable\n",
    "    Returns:\n",
    "    Nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    k = 0\n",
    "    for k1 in range(3):\n",
    "        for k2 in range(3):\n",
    "            k = k + 1\n",
    "            plt.imshow(np.reshape(X[k, :], (28, 28)),\n",
    "                     extent=[(k1 + 1) * 28, k1 * 28, (k2+1) * 28, k2 * 28],\n",
    "                     vmin=0, vmax=255, cmap='viridis')\n",
    "            plt.xlim((3 * 28, 0))\n",
    "            plt.ylim((3 * 28, 0))\n",
    "            plt.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                      labelbottom=False)\n",
    "            plt.clim([0, 250])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_MNIST_weights(weights):\n",
    "    \"\"\"\n",
    "    Visualize PCA basis vector weights for MNIST. Red = positive weights,\n",
    "    blue = negative weights, white = zero weight.\n",
    "    Credit: https://compneuro.neuromatch.io/tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial3.html\n",
    "\n",
    "    Args:\n",
    "    weights (numpy array of floats) : PCA basis vector\n",
    "\n",
    "    Returns:\n",
    "    Nothing.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    cmap = plt.cm.get_cmap('seismic')\n",
    "    plt.imshow(np.real(np.reshape(weights, (28, 28))), cmap=cmap)\n",
    "    plt.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                  labelbottom=False)\n",
    "    plt.clim(-.15, .15)\n",
    "    plt.colorbar(ticks=[-.15, -.1, -.05, 0, .05, .1, .15])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    \n",
    "def get_variance_explained(X):\n",
    "    \"\"\"\n",
    "    Use the covariance matrix to calculate variance explained\n",
    "    along each axis (variable) for the data in X (n obs x n vars).\n",
    "    \n",
    "    NB, uses np.cov(rowvar=False)! \n",
    "    \n",
    "    Args:\n",
    "        X (np array): n obs x n vars matrix\n",
    "        \n",
    "    Returns:\n",
    "        Variance explained by each variable of X (diags of cov)\n",
    "    \"\"\"\n",
    "    cov = np.cov(X, rowvar=False)\n",
    "    return cov[np.eye(X.shape[1]) == 1]\n",
    "\n",
    "\n",
    "# Utility for the bokeh function\n",
    "def embeddable_image(data):\n",
    "    \"\"\"See: https://www.kaggle.com/code/parulpandey/part3-visualising-kannada-mnist-with-umap/notebook\n",
    "    \"\"\"\n",
    "    img_data = 255 - 15 * data.astype(np.uint8)\n",
    "    image = Image.fromarray(img_data, mode='L').resize((28,28), Image.BICUBIC)\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format='png')\n",
    "    for_encoding = buffer.getvalue()\n",
    "    return 'data:image/png;base64,' + base64.b64encode(for_encoding).decode()\n",
    "\n",
    "\n",
    "def hoverable_2d_scatter_with_images(data, labels, unwrapped_images, image_dims, s=4):\n",
    "    \"\"\"\n",
    "    Takes x/y data and makes a scatter plot that is 1) colored by label,\n",
    "    2) hoverable with Bokeh, and 3) optionally has images associated with each point\n",
    "    \n",
    "    Lightly modified from: https://www.kaggle.com/code/parulpandey/part3-visualising-kannada-mnist-with-umap/notebook\n",
    "    \n",
    "    data (np.array): n obs x 2 (x,y)\n",
    "    labels (np.array): n obs\n",
    "    unwrapped_images (np.array): n obs x n pixels\n",
    "    image_dims (tuple or list): width x height to re-wrap images\n",
    "    \"\"\"\n",
    "    \n",
    "    assert data.ndim == 2\n",
    "    assert data.shape[1] == 2\n",
    "    \n",
    "    assert data.shape[0] == labels.shape[0] == unwrapped_images.shape[0]\n",
    "    \n",
    "    assert len(image_dims) == 2\n",
    "    assert np.product(image_dims) == unwrapped_images.shape[1]\n",
    "\n",
    "    rewrapped_images = unwrapped_images.reshape(unwrapped_images.shape[0], image_dims[0], image_dims[1])\n",
    "\n",
    "    digits_df = pd.DataFrame(data, columns=('x', 'y'))\n",
    "    digits_df['digit'] = [str(lab) for lab in labels]\n",
    "    digits_df['image'] = list(map(embeddable_image, rewrapped_images))\n",
    "\n",
    "\n",
    "    datasource = ColumnDataSource(digits_df)\n",
    "    color_mapping = CategoricalColorMapper(factors=[str(9 - x) for x in labels],\n",
    "                                           palette=Spectral10)\n",
    "\n",
    "    plot_figure = figure(\n",
    "        title='UMAP projection of the MNIST dataset',\n",
    "        plot_width=600,\n",
    "        plot_height=600,\n",
    "        tools=('pan, wheel_zoom, reset')\n",
    "    )\n",
    "\n",
    "    plot_figure.add_tools(HoverTool(tooltips=\"\"\"\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src='@image' style='float: left; margin: 5px 5px 5px 5px'/>\n",
    "        </div>\n",
    "        <div>\n",
    "            <span style='font-size: 16px; color: #224499'>Digit:</span>\n",
    "            <span style='font-size: 18px'>@digit</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "    plot_figure.circle(\n",
    "        'x',\n",
    "        'y',\n",
    "        source=datasource,\n",
    "        color=dict(field='digit', transform=color_mapping),\n",
    "        line_alpha=0.6,\n",
    "        fill_alpha=0.6,\n",
    "        size=s\n",
    "    )\n",
    "    show(plot_figure)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd0ad7",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We will start with the MNIST dataset for the first few exercises. This is a set of 70,000 low-res images of handwritten digits. Each image is 28x28, and each image is unwrapped in the data, so we'll be working with a 70,000 x 28^2 (784) matrix. MNIST is a classic machine learning dataset -- many ML researchers spend years trying to shave off tenths of percentage points of accuracy on it! See eg: https://benchmarks.ai/mnist. It is generally considered to be an easy problem in machine learning; very simple classifiers perform >90% accurate.\n",
    "\n",
    "Here, we won't bother with classification, but the semantic meaning of the data points as numbers will help us to understand what PCA is doing with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mnist data (takes ~30 seconds)\n",
    "mnist = fetch_openml(name='mnist_784', as_frame = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fc48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data.astype('int')\n",
    "y = mnist.target.astype('int')  # 70,000-integer vector; tells which digit is represented by each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd34395",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize nine of the images\n",
    "plot_MNIST_sample(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0d1cf",
   "metadata": {},
   "source": [
    "## PCA Visualization\n",
    "This PCA tutorial is partially borrowed / entirely inspired by NeuroMatch Academy's Dimensionality Reduction tutorial: https://compneuro.neuromatch.io/tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial3.html\n",
    "\n",
    "Let's run PCA on the MNIST dataset and see what we get. Scikit-learn has a [handy PCA object](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) that takes care of the math for us. Run the following cells and then answer questions 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea34abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize a pca model\n",
    "pca = PCA(random_state=2022)\n",
    "\n",
    "# TODO: Normalize each variable (ie columnn) (ie pixel position) by subtracting its mean across the dataset\n",
    "X_norm = ...\n",
    "\n",
    "# TODO: Run PCA on the data (\"fit\"), and return the representation of the data in the new coordinates (\"transform\")\n",
    "pca.fit(...)\n",
    "X_transform = ...\n",
    "\n",
    "# Extract PCs and var explained from the model object\n",
    "components = pca.components_\n",
    "explained_variance = pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ef5b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the data in the new coordinates\n",
    "x_pc = 0\n",
    "y_pc = 1\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(X_transform[:,x_pc], X_transform[:,y_pc], s=2, c=y, cmap='tab10')\n",
    "plt.xlabel('PC1', fontsize=18)\n",
    "plt.ylabel('PC2', fontsize=18)\n",
    "plt.title('MNIST in the reduced PCA space', fontsize=18)\n",
    "plt.colorbar(ticks=range(10))\n",
    "plt.clim(-0.5, 9.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d8895",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the components (each 1 x num pixels) as if they were also digits\n",
    "for i in range(3):\n",
    "    plot_MNIST_weights(components[i,:])\n",
    "    plt.title(f'MNIST PC {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the explained variance vs the i-th PC\n",
    "plt.plot(explained_variance)\n",
    "plt.xlabel('Component number')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Scree plot for MNIST PCA (variance explained by i-th component)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac2f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO (Q2): what percentage of the total variance does the first principal component explain?\n",
    "percent_explained_PC1 = ...\n",
    "\n",
    "print(percent_explained_PC1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663552f6",
   "metadata": {},
   "source": [
    "**QUESTION 1:** Which of the following questions does PCA analysis help to answer?\n",
    "* Which set of new vectors best reconstrcut the original data?\n",
    "* Which set of predictors are maximally uncorrelated with each other?\n",
    "* Which set of predictors describe the axes along which the data vary most?\n",
    "\n",
    "**QUESTION 2:** What percentage of the total variance (rounded to one decimal) does PC1 explain?\n",
    "\n",
    "**QUESTION 3:** in the scatter plot of PC1 vs. PC2, what does each point represent?\n",
    "* One picture from the dataset\n",
    "* One pixel from one picture from the dataset\n",
    "* One component of the PCA results\n",
    "\n",
    "**QUESTION 4:** How would you interpret PC1's meaning, in the context of MNIST? What does it tell you about the digits in the dataset?\n",
    "\n",
    "**QUESTION 5:** About how many principal components would you use to reconstruct the MNIST dataset with high accuracy but substantially reduced dimensionality? \n",
    "* 2\n",
    "* 20\n",
    "* 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: using the number of PCs from question 5, reconstruct the orginal MNIST dataset \n",
    "# from the transformed data and the principal components. Then determine the mean squared error for your reconstruction.\n",
    "\n",
    "# Hint: you'll need to use matrix multiplication, and don't forget to add back the column means!\n",
    "\n",
    "n_pcs_to_use = 20\n",
    "X_reconstructed = ...\n",
    "reconstruction_pca_mse = np.mean((X - X_transform)**2)\n",
    "print(reconstruction_pca_mse)\n",
    "\n",
    "plot_MNIST_sample(X_reconstructed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26661a",
   "metadata": {},
   "source": [
    "**QUESTION 6:** What is the mean squared error for your reconstruction?\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ecc04",
   "metadata": {},
   "source": [
    "You should see readable, if slightly blurry, digits in the plot above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c22e61",
   "metadata": {},
   "source": [
    "## Comparing PCA to random projections\n",
    "Another common technique for performing dimensionality reduction (although it is becoming less common as computers get faster) is using random projections. Instead of calculating the optimal set of projection axes (i.e. the principal components), we just use random ones that happen to have decent statistical properties, on average.\n",
    "\n",
    "Here, we compare one type of random projections to PCA, based on variance explained by the axes of the projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7813c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "n_iter = 100\n",
    "np.random.seed(2022)\n",
    "\n",
    "# TODO: simulate many different random projections of the MNIST dataset. \n",
    "# Get the maximum variance explained by any single dimension of the transformed data, \n",
    "# and compare the distribution of these values to the maximum variance explained from PCA (ie PC1).\n",
    "\n",
    "# Hint: use the sklearn SparseRandomProjection function, and the helper function get_variance_explained(), defined above.\n",
    "\n",
    "max_var_explained = np.zeros(n_iter,)\n",
    "for i in range(n_iter):\n",
    "    sparse_rand_proj = ...\n",
    "    X_rand = ...\n",
    "    max_var_explained[i] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9bd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(max_var_explained, label='Max of random')\n",
    "plt.axvline(explained_variance[0], color='r', label='PC1')\n",
    "plt.xlabel('Variance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d79ad39",
   "metadata": {},
   "source": [
    "**QUESTION 7:** On average, how many times more/less variance does the best sparse projection component explain than the first principal component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: answer question 7\n",
    "variance_ratio = ...\n",
    "variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a1b9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: similar to how you did above, reconstruct the original MNIST data from a sparse random projection.\n",
    "# Then calculate the MSE, and visualize it.\n",
    "\n",
    "n_sparse_projs_to_use = int(variance_ratio * n_pcs_to_use) # Multiply these so that the reconstructions explain roughly similar amounts of variance.\n",
    "sparse_rand_proj = ...\n",
    "X_rand = ...\n",
    "X_reconstructed_from_sparse = ...\n",
    "\n",
    "\n",
    "plot_MNIST_sample(X_reconstructed_from_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afcb59f",
   "metadata": {},
   "source": [
    "**QUESTION 8:** How does the sparse random reconstruction differ from the PCA-based reconstruction? Explain why it differs in this way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c3455",
   "metadata": {},
   "source": [
    "Before we leave PCA, it is worth acknowledging that there are lots of other linear dimensionality reduction algorithms out there. If you're interested in applying dimensionality reduction to neural activity, I highly recommend [this video](https://youtu.be/zeBFyRaoVnQ?t=1394) by Byron Yu; this link points you to the part of the video where he covers a bunch of different techniques and when you might use each one. Very useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe9c28",
   "metadata": {},
   "source": [
    "## UMAP for clustering\n",
    "\n",
    "Now, let's run UMAP on the same dataset and see how the results differ from PCA. Run the cells, then answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad53dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell may take 1-2 minutes\n",
    "\n",
    "# Initialize the UMAP model for 2d \n",
    "umap_model = umap.UMAP(n_components=2, random_state=2022)\n",
    "\n",
    "# Run UMAP on the data (\"fit\"), and return the representation of the data in the new coordinates (\"transform\")\n",
    "umap_model.fit(...)\n",
    "embedding = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data with UMAP's built-in plotting utility; this uses datashader on the backend to make a nice tidy plot\n",
    "umap.plot.points(umap_model, labels=y)\n",
    "hover_data = pd.DataFrame({'index':np.arange(X.shape[0]),\n",
    "                           'label':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb1a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the data with an interactive package called holoviews (Bokeh)\n",
    "\n",
    "# Start Bokeh\n",
    "output_notebook()\n",
    "\n",
    "# Make the plot\n",
    "hoverable_2d_scatter_with_images(embedding, y, X, (28,28), s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf18b5d",
   "metadata": {},
   "source": [
    "**QUESTION 9:**: UMAP appears to separate the digits far better than PCA did. This suggests that the data are separable in what way?\n",
    "* Linearly\n",
    "* Non-linearly\n",
    "* Uniformly\n",
    "\n",
    "**QUESTION 10:** UMAP attempts to preserve local structure in the data. Using the hover tooltip, examine the way that the digits change within each digit cluster (i.e. from the top to bottom of all the 1's). Did UMAP appear to preserve local structure in this case?\n",
    "\n",
    "**QUESTION 11:** Zoom into the left edge of the 6's cluster. You should see a few points that are not 6's (colored differently). Examine the corresponding images. What happened here -- did UMAP make a mistake?\n",
    "\n",
    "**QUESTION 12:** Compare and contrast the insights into the MNIST dataset that PCA and UMAP give us. Which do you feel reveals more about the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481bb8a7",
   "metadata": {},
   "source": [
    "## \"The Specious Art of Single-Cell Genomics\"\n",
    "\n",
    "This exercise recreates a piece of data from Chari et al. 2021, a paper from Lior Pachter's lab that examines the use of clustering algorithms like PCA and UMAP in the analysis of single-cell RNA sequencing data. The paper's main argument is that investigators should not do quantifications in UMAP output space (i.e. cell-to-cell distance, relative spacing of different cell types, \"trajectories\") in order to draw conclusions about biological variables of interest, because UMAP distorts the data too heavily to be interpretable. \n",
    "\n",
    "Their line of reasoning is two-fold. First, it is impossible to reduce high-dimensional data to low-dimensional data without distorition; this is a mathematical fact, and is unavoidble. So, second, the authors ask, how good of a job does UMAP do at doing that reduction, given the inevitable distortions? The authors argue that it does a very bad job, and to prove their point, they design an auto-encoder that, by their metrics, performs just as well as UMAP in maitaining the characteristics of the original data, but shapes the 2D data in any way you like (for example, an elephant or a world map). \n",
    "\n",
    "Here, we recreate one piece of data from their Figure 2b: the correlation between all inter-cell-type distances as measured in ambient space (log-normalized counts), PCA space, or PCA-UMAP space. Put another way: given a gene expression dataset with $T$ cell types, first find the centroid (mean) of each cell type, then find the set of $T*(T-1)/2$ inter-centroid distances. Repeat that calculate for the ambient, PCA, and PCA-UMAP spaces. Finally, correlate the $T*(T-1)/2$-length vectors in pairs (ambient vs PCA, ambient vs PCA-UMAP) and see how the UMAP correlation compares to the PCA correlation.\n",
    "\n",
    "A technical note: in single-cell analysis, it is standard practice to perform UMAP *on top of* PCA. That is, one first runs PCA on the data; then one runs UMAP on the output of the PCA. This is because UMAP tends to fail in very high dimensions (i.e. many thousands, which is what single cell analyses often have), but PCA can help reduce that number to ~50 or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d718654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_path = '/Users/jonahpearl/Documents/PiN/G3/TAD/TAD_python/data'\n",
    "count_mat = sio.mmread(os.path.join(data_path, 'tenx.mtx'))\n",
    "count_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(os.path.join(data_path, 'metadata.csv'), index_col=0)\n",
    "print(meta.shape)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f254fa",
   "metadata": {},
   "source": [
    "Let's briefly examine the data.\n",
    "\n",
    "**QUESTION 13**: How many genes are present in this dataset? How many cells? (Hint: think about what count_mat and meta each represent.) \n",
    "\n",
    "**QUESTION 14**: Which of these is represents the dimensionality of the data?\n",
    "\n",
    "**QUESTION 15**: How many unique cell types (\"clusters\") are there in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: find the number of unique cell types in the data set (hint -- this can be done in one simple line of code!)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65a9e4",
   "metadata": {},
   "source": [
    "Let's find the centroids for each cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write a function to find the centroids for each cluster.\n",
    "# We define the centroid of a cluster to be the average of all cells in that cell type.\n",
    "\n",
    "def get_centroids(counts, cluster_labels):\n",
    "    \"\"\"Get centroids of clusters in a set of points\n",
    "    Arguments:\n",
    "        counts {np.array} -- a cells x genes matrix of rna counts\n",
    "        cluster_labels {array or list} -- cluster labels for each cell\n",
    "    \n",
    "    Returns:\n",
    "        clusters {np.array} -- list of all unique clusters\n",
    "        centroids {np.array} -- the centroid for each corresponding cluster\n",
    "    \"\"\"\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    centroids = np.zeros((len(unique_clusters), counts.shape[1]))\n",
    "    \n",
    "    for i in range(len(unique_clusters)):\n",
    "        cells_in_cluster = ...\n",
    "        centroids[i, :] = ...\n",
    "    \n",
    "    return unique_clusters, centroids\n",
    "\n",
    "# Use your function to get the centroids for each cluster in the ambient space (count_mat)\n",
    "clusters, centroids = get_centroids(count_mat, meta.cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d28c92",
   "metadata": {},
   "source": [
    "**QUESTION 16:** What is the value of the second dimension of the centroid of the Esr1_6 cells?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540546fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find the value of the second dimension of the centroid of the Esr1_6 cells\n",
    "esr1_6_idx = ...\n",
    "centroids[esr1_6_idx][0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864643ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write a function that gets the T(T-1)/2 inter-centroid distances, and returns them as a single vector.\n",
    "# We will use L1 distance, which is more suitable for sparse high dimensional data than L2.\n",
    "def get_pairwise_dists(points):\n",
    "    \"\"\"Get pairwise L1 distances of a set of points\n",
    "    Arguments:\n",
    "        points {np.array} -- a points x dimensions matrix\n",
    "    Returns:\n",
    "        dists {np.array} -- a vector of size N*N-1 pairwise distances\n",
    "    \"\"\"\n",
    "    \n",
    "    all_dists = ...  # hint: check out scipy.metric.pairwise_distances. Make sure to use the L1 norm!\n",
    "    \n",
    "    # Remove redundant pairs\n",
    "    dists = np.triu(all_dists)\n",
    "    dists = dists[dists != 0]\n",
    "    \n",
    "    return dists\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c0256",
   "metadata": {},
   "source": [
    "**QUESTION 17**: What is the mean pairwise distance between clusters in the ambient space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc34492",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_dist_vector = get_pairwise_dists(centroids)\n",
    "pairwise_dist_vector.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e0ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there are the expected number of inter-centroid distance values\n",
    "assert pairwise_dist_vector.shape[0] == centroids.shape[0]*(centroids.shape[0] - 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15078325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pca_and_umap(counts, n_pcs=50, n_umap_components=2):\n",
    "\"\"\" This function returns PCA and PCA-UMAP representations of the input data\n",
    "\"\"\"    \n",
    "    print('Scale')\n",
    "    # Scale the data for PCA\n",
    "    scaled_mat = scale(counts)\n",
    "    \n",
    "    print('PCA')\n",
    "    # Get the PCA object\n",
    "    tsvd = TruncatedSVD(n_components=n_pcs)\n",
    "    \n",
    "    # Run PCA\n",
    "    x_pca = tsvd.fit_transform(scaled_mat)\n",
    "    \n",
    "    print('UMAP')\n",
    "    # Get the UMAP object\n",
    "    reducer = umap.UMAP(n_components=n_umap_components)\n",
    "    \n",
    "    # Run UMAP. Note that we purposely run UMAP on the output of the PCA!\n",
    "    x_pca_UMAP = reducer.fit_transform(x_pca)\n",
    "    \n",
    "    return x_pca, x_pca_UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b75d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PCA and UMAP representations of the data\n",
    "counts_pca, counts_pca_UMAP = get_pca_and_umap(count_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd65708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get pairwise distance vectors and correlate to ambient\n",
    "...\n",
    "pairwise_dist_vector_pca = ...\n",
    "\n",
    "...\n",
    "pairwise_dist_vector_UMAP = ...\n",
    "\n",
    "print(np.corrcoef(pairwise_dist_vector, pairwise_dist_vector_pca)[0,1])\n",
    "print(np.corrcoef(pairwise_dist_vector, pairwise_dist_vector_UMAP)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596590d",
   "metadata": {},
   "source": [
    "**QUESTION 18:** What is the correlation between the ambient and UMAP space?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2aaa6",
   "metadata": {},
   "source": [
    "Now, use bootstrapping to estimate the standard error of these correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e880372",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: bootstrap the correlations\n",
    "n_iters = 10  # each iteration takes ~10-20 seconds, so don't do too many!\n",
    "amb_pca_corrs = np.zeros(n_iters)\n",
    "amb_UMAP_corrs = np.zeros(n_iters)\n",
    "np.random.seed(10)\n",
    "for i in range(n_iters):\n",
    "    print(i)\n",
    "    \n",
    "    # Resample from the data\n",
    "    ...\n",
    "    \n",
    "    # Get PCA and UMAP representations of the re-sampled data\n",
    "    ...\n",
    "    \n",
    "    # Find cluster centroids in the re-sampled data\n",
    "    ...\n",
    "    \n",
    "    # Get pairwise distances between centroid pairs in each latent space\n",
    "    ambient_dists = ...\n",
    "    pca_dists = ...\n",
    "    umap_dists = ...\n",
    "    \n",
    "    # Correlate the distances in ambient spce to PCA and UMAP\n",
    "    amb_pca_corrs[i] = ...\n",
    "    amb_UMAP_corrs[i] = ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the bootstrapping\n",
    "from seaborn import pointplot\n",
    "corrs_df = pd.DataFrame({'pca': amb_pca_corrs, 'pca_UMAP': amb_UMAP_corrs}).melt(var_name='latent', value_name='corr_to_ambient')\n",
    "pointplot(data=corrs_df, y='corr_to_ambient', x='latent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d9d28",
   "metadata": {},
   "source": [
    "**QUESTION 18**: What is the standard error for the correlation between the ambient and UMAP data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287753e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = ...\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce34ad81",
   "metadata": {},
   "source": [
    "**QUESTION 19**: Generate a p-value for the hypothesis that the correlation between the ambient and the UMAP representations is significantly lower than the correlation between the ambient and the PCA representations. Is there a real effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ranksums(..., ... alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be609b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753158d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

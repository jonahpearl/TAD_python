{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1N_9rxPwRS8r"
   },
   "source": [
    "# Bootstrap example for Stroke data from pp. 3-5 of Efron & Tibshirani\n",
    "\n",
    "RTB wrote it 29 October 2016 (derived from BS_ex1.m)\n",
    "RTB modified it 30 Jan 2017: combined etASAhypoth.m and etASAstats.m into\n",
    "one file that is modular for my stats class.\n",
    "RTB modified it to emphasize stroke data (13 September 2018). ERBB translated to Python 08 September 2021. JP added short pandas intro Aug 2022. \n",
    "\n",
    "**The scenario**:\n",
    "\n",
    " A study was done to see if low-dose aspirin would prevent\n",
    "heart attacks in healthy middle-aged men. The study design was optimal:\n",
    "controlled, randomized, double-blind. Subjects were randomly assigned to\n",
    "receive aspirin (ASA) or placebo. The summary statistics:\n",
    "\n",
    "aspirin group (n=11037): 104 heart attacks (MI); 10933 no MI\n",
    "placebo group (n=11034): 189 heart attacks; 10845 no MI\n",
    "\n",
    "Scientific question #1: Does aspirin help to prevent heart attacks?\n",
    "\n",
    "In the same study, the researchers also recorded the number of strokes in\n",
    "each group:\n",
    "\n",
    "aspirin group (n=11037): 119 strokes; 10918 without stroke\n",
    "placebo group (n=11034): 98 strokes; 10936 without stroke\n",
    "\n",
    "Scientific question #2: Does aspirin increase the risk of having a\n",
    "stroke?\n",
    "\n",
    "We will start by addressing the 2nd question regarding strokes. The code\n",
    "you generate here will then allow you to rapidly analyze the heart attack\n",
    "data.\n",
    "\n",
    "**What to do:** \n",
    "\n",
    "Login to learning catalytics and join the session for the\n",
    "module entitled \"ASA Bootstrap\". You will answer a series of\n",
    "questions based on the guided programming below. \n",
    "\n",
    "Read through the comments and follow the instructions provided.\n",
    "In some cases you will be asked to answer a question, clearly indicated\n",
    "by 'QUESTION'. In other cases, you be asked to supply missing code,\n",
    "indicated by 'TODO'. The corresponding question in learning catalytics\n",
    "will be indicated in parentheses (e.g. Q1). If there is no 'Q#'\n",
    "accompanying a 'QUESTION' just type your answer into this script and\n",
    "discuss it with your team. Once you have supplied the required code, you\n",
    "can execute that section by mouse-clicking in that section (The sidebar will turn blue/green.) and then simultaneously hitting the 'ctrl' and 'enter'\n",
    "keys (PC) or 'command' and 'enter' keys (Mac).\n",
    "\n",
    "\n",
    "**Concepts covered:**\n",
    "1. Test for proportions: odds ratio\n",
    "2. Comparing resampling tests with Fisher's exact test\n",
    "3. Std. error and confidence intervals through bootstrapping\n",
    "4. Relationship between CI and hypothesis test\n",
    "5. Permutation test for strong test of H0.\n",
    "6. One-tailed vs. two-tailed tests.\n",
    "7. CI with 'bootci' and an anonymous function\n",
    "8. Making data tables with 'table' command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "os-GAIZtZGK8"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Pandas Intro (Python Only)\n",
    "\n",
    "Until now, we have only been using Numpy for handling our data. This results in having to do slightly awkward things, like when we created variables to store column indices in week 2:\n",
    "```\n",
    "# Define cols\n",
    "ID_COL = 0\n",
    "GRE_COL = 1\n",
    "GPA_COL = 2\n",
    "```\n",
    "\n",
    "In general, this is tedious, and it also forces us to keep track of all the data-handling logic ourselves. For instance, in the GRE data, what if we had another list that gave the country or state where each student had gone to high school? We would need to remember that variable name too! As we accumulated more data, it would become a nightmare. Luckily, for this reason we have tabular data!\n",
    "\n",
    "In Python, the most commonly used tabular data package is called Pandas. As the [first tutorial](https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html#min-tut-01-tableoriented) on their site explains, in Pandas, \"a DataFrame is a 2-dimensional data structure [a table] that can store data of different types (including characters, integers, floating point values, categorical data and more) in columns.\" This makes it incredibly flexible and powerful.\n",
    "\n",
    "Here we will demonstrate a few of the typical usage cases you'll need for the rest of this class. Don't hesitate to browse the [user guide](https://pandas.pydata.org/docs/user_guide/index.html) or their [full documentation ](https://pandas.pydata.org/docs/reference/index.html) or just google search \"pandas XYZ\" where XYZ is the operation you want! Feel free to skip this section if you're familiar with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some fake data\n",
    "names = ['Alice', 'Bob', 'Cathy', 'Donald']\n",
    "ages = [10, 20, 30, 40]\n",
    "gre_scores = [500, 600, 700, 650]\n",
    "df = pd.DataFrame({'names': names, 'ages': ages, 'gre_scores': gre_scores})\n",
    "df.head()  # .head() shows the first 5 rows of a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that both the rows and the columns are named, with the names shown in bold. The rows have been named 0,1,2,3 by default, since we didn't provide anything else; and the columns have been given the names that we put in the dictionary above when we made the DataFrame using `pd.DataFrame()`. The names of the rows are called the DataFrame's index, and the column names are called...the columns. An \"index\" is actually a special kind of object in Pandas. If you want to see all the values of dataframe's index (i.e. all the row names), you can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see all the column names you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you work with data in a DataFrame? Your first instinct to access data in a DataFrame might be to do something like `df[0,1]` (if you wanted to know Alice's age [0th row, 1st column]). However, this will raise a KeyError -- go ahead and try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[0,1]  # raises an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because DataFrames are not quite as simple as Numpy arrays!\n",
    "\n",
    "Instead, there are three main ways to access data in a Pandas dataframe. We will explain each. \n",
    "\n",
    "**Working with columns**\n",
    "\n",
    "The first is by using \"dot\" or \"bracket\" notation to access individual columns. The columns are then indexed in a straightforward way. Whether to use dot or bracket notation largely depends on personal preference. Strictly speaking, bracket notation is better because it is guaranteed to work — e.g. if the column name contains a space, dot notation won't work — but I prefer dot notation because it's faster to type, and so all my column names have underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dot notation:')\n",
    "print(df.gre_scores)\n",
    "print()\n",
    "\n",
    "print('Bracket notation:')\n",
    "print(df['gre_scores']) # same thing as df.gre_scores\n",
    "print()\n",
    "\n",
    "print('Multiple cols with bracket notation:')\n",
    "print(df[['gre_scores', 'ages']])  # we can get multiple columns with a list of column names\n",
    "print()\n",
    "\n",
    "print(f'Alice\\'s GRE score: {df.gre_scores[0]}')  # easy zero-based indexing within a column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Here is an example of dot notation in action:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "older_than_20 = df.names[df.ages > 20]  # Boolean indexing works equally well here as in numpy\n",
    "older_than_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: repeat the above operation but with bracket notation\n",
    "older_than_20 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Warning*: Notice that the output `older_than_20` still has the original index values (2 and 3) associated with it. If this is ever causing bugs in your code you can always reset the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "older_than_20 = older_than_20.reset_index(drop=True)\n",
    "older_than_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with rows and columns: loc**\n",
    "\n",
    "The second method is using the `.loc` method. This allows you to access data by row and column index. This example makes more sense if we use subject names as an index, so we will change it. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('names')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the row names have become the subject names!\n",
    "\n",
    "We can access data by row and column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['Alice', 'Cathy'], 'gre_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.ages > 20, 'gre_scores']  # boolean indexing also works here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with integer indices: iloc**\n",
    "\n",
    "The third method is the `.iloc` method. This allows you to use the integer-position of the row to select. This is essentially the same as having the index be 0,1,2,3... but in cases where you have a more meaningful index, this can be helpful if you want to know the i-th entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, you can avoid iloc with various combinations of the first two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few other useful points\n",
    "\n",
    "Pandas has many built in simple statistics. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sums:')\n",
    "print(df.sum())\n",
    "print()\n",
    "\n",
    "print('Means:')\n",
    "print(df.mean())\n",
    "print()\n",
    "\n",
    "print('Variances:')\n",
    "print(df.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also has a **convenient built-in [.sample()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method** which can replace np.random.choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=10, replace=True, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Pandas has a **convenient .dropna() method** which can save you some time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['NoName', ['ages', 'gre_scores']] = [np.nan, np.nan]\n",
    "print(df)\n",
    "print(df.dropna(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY8N6GqITfkz"
   },
   "source": [
    "##  Calculate the actual ratio of rates of disease: an odds ratio\n",
    "\n",
    "Ok, back to statistics! \n",
    "\n",
    "Recall Scientific question #1: Does aspirin help to prevent heart attacks?\n",
    "\n",
    "The odds ratio is defined as the ratio of 2 ratios: the numerator is the ratio of\n",
    "the number of subjects in the treatment group who had a stroke divided by\n",
    "the number who did not have a stroke. The denominator is the same, but\n",
    "for the control group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K3BV7sU8RWo5"
   },
   "outputs": [],
   "source": [
    "# Constants: these would normally be passed as arguments to a function\n",
    "\n",
    "n_boot = 10000\n",
    "my_alpha = 0.05\n",
    "\n",
    "# useful numbers for stroke data\n",
    "n_rx = 11037  # total number of patients in the treatment group (ASA)\n",
    "n_stroke_rx = 119  # number of strokes in the treatment group\n",
    "n_ctrl = 11034  # total number of patients in the control group (placebo)\n",
    "n_stroke_ctrl = 98  # number of strokes in the control group\n",
    "n_total = n_rx + n_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1631699586374,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "aS6Sbk6LTp_Y",
    "outputId": "0c62f5fd-0e46-46b3-e10c-0e7bce62623e"
   },
   "outputs": [],
   "source": [
    "# TODO: calculate the odds ratio for this study\n",
    "or_hat = ...\n",
    "\n",
    "print(or_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoLLEXShTlXU"
   },
   "source": [
    "**QUESTION (Q1)**: What is your odds ratio to 4 decimal places?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqVJzroDUmVh"
   },
   "source": [
    "## Create a population from which to resample:\n",
    "\n",
    "The general approach in bootstrapping is to resample from our *original\n",
    "sample*. But you've been given only proportions, so you have to\n",
    "*re-create* the raw data based on the proportions. It's alarmingly\n",
    "simple, but you might have to think about it for a bit. (Note that we won't use the tidy format here to sync better with Matlab)\n",
    "\n",
    "HINT: You should be able to re-calculate your original odds ratio with this formula:\n",
    "`( data['rx_grp'].sum() / (data['rx_grp'] == 0).sum() ) / ( data['ctrl_grp'].sum() / (data['ctrl_grp'] == 0).sum() )`. Notice the use of bracket notation to access the columns, and the .sum() method to get the sum of each column.\n",
    "\n",
    "THINK: what does it mean when we call `.sum()` on the result of `(data['rx_grp'] == 0)`, which would be a boolean? If you're not sure, try some simple examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1631699603604,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "UI1UF8fA0n_P",
    "outputId": "51e31545-4d3e-43f4-dc0f-776fe2756e63"
   },
   "outputs": [],
   "source": [
    "n_rows = np.max([n_ctrl, n_rx])\n",
    "\n",
    "data = pd.DataFrame({'ctrl_grp': np.nan * np.ones((n_rows,)),\n",
    "                     'rx_grp': np.nan * np.ones((n_rows, )) })\n",
    "\n",
    "# TODO: recreate the raw data\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1631699604046,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "vX-cbCgrw5BP",
    "outputId": "959fcffe-1e49-428a-a22d-f20bc5ec1861"
   },
   "outputs": [],
   "source": [
    "( data['rx_grp'].sum() / (data['rx_grp'] == 0).sum() ) / ( data['ctrl_grp'].sum() / (data['ctrl_grp'] == 0).sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdhIAv7E4a6D"
   },
   "source": [
    "Note that we have some NaNs to make these columns the same size. To grab the non-Nan data, which you'll need to do below, use `data['ctrl_grp'].dropna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTIaiqb5ba8g"
   },
   "source": [
    "## Generate bootstrap replicates of the odds ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "error",
     "timestamp": 1631702365931,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "jt49G-WTvuCA",
    "outputId": "2ea16f04-68ec-49ec-f127-521edc1e0d54"
   },
   "outputs": [],
   "source": [
    "# holds each bootstrap calc. of the odds ratio\n",
    "or_bootstrap = pd.DataFrame({'or_star': np.zeros((n_boot,))}) \n",
    "\n",
    "# set random seed\n",
    "np.random.seed(123)\n",
    "\n",
    "for k in range(n_boot):\n",
    "\n",
    "    # TODO: Re-sample from each group WITH REPLACEMENT to create two new\n",
    "    # samples: rx_star and ctrl_star. Then use these two bootstrap samples to\n",
    "    # calculate an odds ratio and store it in or_bootstrap['or_star']\n",
    "    rx_star = ...\n",
    "    ctrl_star = ...\n",
    "    or_bootstrap.loc[k, 'or_star'] = ...                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "218wwd1fjC_t"
   },
   "source": [
    "## Make a histogram of our bootstrap replicates of OR\n",
    "\n",
    "Here, we also introduce seaborn (imported as `sns`), a plotting package that is basically a fancy wrapper for matplotlib that works easily with Pandas DataFrames.\n",
    "\n",
    "In general, seaborn expects you to be plotting different columns of a DataFrame against each other, or making histograms out of single columns. Trying to do anything else will result in frustration and you should just make the plot manually!\n",
    "\n",
    "For most seaborn functions (which you can browse in a beautiful gallery [here](https://seaborn.pydata.org/examples/index.html)), the syntax is:\n",
    "```\n",
    "sns.plotting_function(data = my_pandas_dataframe, x = \"column_1\", y = \"column_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1631699851205,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "Hu1seBHk28dq",
    "outputId": "d8e09757-6326-4537-d0ee-45ffd828965a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "sns.histplot(data = or_bootstrap, x = 'or_star', ax = ax)  # no \"y\" argument since histograms only have one data axis\n",
    "\n",
    "ax.plot([or_hat, or_hat], ax.get_ylim(), 'lime', lw = 2)\n",
    "ax.set(xlabel = 'OR^*',\n",
    "       ylabel = '#',\n",
    "       title = 'Distribution of bootstrapped odds ratios');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx_4ZTkDdrY6"
   },
   "source": [
    "## Calculate the standard error and the confidence intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1631699883246,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "QJVA54V_djdz",
    "outputId": "f5e39fc5-8358-44da-c58b-b9777f537d5d"
   },
   "outputs": [],
   "source": [
    "# TODO: Compute the bootstrap estimate of the standard error of the odds ratio\n",
    "sem_boot = ...\n",
    "\n",
    "sem_boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u70xYn0Bd8IK"
   },
   "source": [
    "**QUESTION (Q2)**: What is bootstrap estimate of the standard error of the odds ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1631699960622,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "zEw-6M7u3o0T",
    "outputId": "a302006f-ded1-4645-fc0e-0fe974c85bc9"
   },
   "outputs": [],
   "source": [
    "# TODO: Use the percentile method to determine the 95% confidence interval.\n",
    "...\n",
    "\n",
    "conf_interval = ...\n",
    "\n",
    "print(conf_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtpG3fJkezOf"
   },
   "source": [
    "**QUESTION (Q3)**: What is the 95% CI based on your bootstrap distribution?\n",
    "\n",
    "**QUESTION (Q4)**: What is the null value of the odds ratio?\n",
    "\n",
    "**QUESTION (Q5)**: How can we use the known null value of the odds ratio to\n",
    "perform a hypothesis test?\n",
    "\n",
    "**QUESTION (Q6)**: Can we reject H0 at an alpha of 0.05?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TlwGD3-hhbF"
   },
   "source": [
    "## Plot CIs on histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1631699985870,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "Rso8jYAs4Czy",
    "outputId": "a51795d0-4196-4be0-ec7f-2cbae88dc78b"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.histplot(data = or_bootstrap, x = 'or_star');\n",
    "\n",
    "ylims = ax.get_ylim()\n",
    "\n",
    "ax.plot([or_hat, or_hat], ylims, 'lime', lw = 2, label = 'or_hat')\n",
    "\n",
    "# Add CIs\n",
    "ax.plot([conf_interval[0], conf_interval[0]], ylims, 'r', label = '95% CI')\n",
    "ax.plot([conf_interval[1], conf_interval[1]], ylims, 'r')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set(xlabel = 'OR^*',\n",
    "       ylabel = '#',\n",
    "       title = 'Distribution of bootstrapped odds ratios');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wSF8U0Ll0pM"
   },
   "source": [
    "## Bonus: 2-sided p-value from the bootstrap distribution\n",
    "\n",
    "We can get a more exact 2-sided p-value by gradually shrinking our CI\n",
    "until the null value falls just outside. We have already done the hard\n",
    "work of generating the bootstrap distribution and sorting it, so now we\n",
    "just loop through and find the value of alpha that puts the null value of\n",
    "1 outside of the lower bound.\n",
    "\n",
    "NOTE: In the code below, we are taking advantage of our prior knowledge\n",
    "that it is the lower bound of the CI that we should be testing. But\n",
    "realize that we are effectively *shrinking* the CI in the 'while' loop:\n",
    "the upper bound of the CI would be decreasing, just as the lower bound is\n",
    "increasing. We just aren't bothering to calculate it, because it doesn't\n",
    "matter. If our calculated odds ratio was below 1, then we would test the\n",
    "upper bound as we shrunk the CI.\n",
    "\n",
    "\n",
    "NOTE: This cell won't work for the MI data, since our bootstrapped distribution won't contain the null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1631700008353,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "TK2pnh_BBx3o",
    "outputId": "d700563a-7d4a-430c-aa51-d6f155d76520"
   },
   "outputs": [],
   "source": [
    "ci_low = conf_interval[0]\n",
    "p_alpha = my_alpha\n",
    "    \n",
    "while ci_low < 1:\n",
    "\n",
    "    # increment alpha\n",
    "    p_alpha += 0.001\n",
    "    \n",
    "    # calculate new index corresponding to lower %ile:\n",
    "    idx_lo = np.floor(( p_alpha / 2 ) * n_boot).astype('int')\n",
    "    \n",
    "    # grab the corresponding value from our sorted bootstrap distribution\n",
    "    ci_low = or_star_sorted[idx_lo]\n",
    "\n",
    "print(p_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RgOc8ZwkjMr"
   },
   "source": [
    "## Perform an explicit hypothesis test by modeling our OR under H0\n",
    "\n",
    "In this case, we will use a permutation test, where we resample WITHOUT\n",
    "replacement. The logic is that we are essentially randomly assigning each\n",
    "patient to the treatment or control group, then recalculating our odds\n",
    "ratio. Here, we are testing the most extreme version of H0, which is that\n",
    "the two distributions are the SAME.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZJpNVh-4Wcy"
   },
   "outputs": [],
   "source": [
    "# # TODO: Perform resampling as though the patients all belonged to the\n",
    "# same group (called H0_data), shuffle this data, then arbitraily assign\n",
    "# each patient to the treatment or control group and compute the odd ratio. \n",
    "# Store each bootstrapped odds ratio in orPerm\n",
    "\n",
    "# Pool all the data:\n",
    "H0_data = pd.concat([data['rx_grp'].dropna(), data['ctrl_grp'].dropna()])\n",
    "\n",
    "# Place to store our results:\n",
    "or_bootstrap['or_perm'] = np.zeros((n_boot,))\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(123)\n",
    "\n",
    "# Loop over bootstraps\n",
    "for k in range(n_boot):\n",
    "\n",
    "    # Shuffle and assign to rx_star and ctrl_star (ALL values are used!)\n",
    "    ...\n",
    "\n",
    "    or_bootstrap.loc[k, 'or_perm'] = ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM9j-iK7n8_I"
   },
   "source": [
    "## Plot the distrubtion of permuted ORs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1631700098135,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "RFttsris7-JS",
    "outputId": "c19e1bf4-9cc8-4c8c-bbfa-78cd2c80f6eb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.histplot(data = or_bootstrap, x = 'or_perm');\n",
    "\n",
    "ylims = ax.get_ylim()\n",
    "\n",
    "ax.plot([or_hat, or_hat], ylims, 'lime', lw = 2, label = 'or_hat')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set(xlabel = 'Permuted ORs',\n",
    "       ylabel = '#',\n",
    "       title = 'Distribution of ORs under H0');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJfWoCONiFjU"
   },
   "source": [
    "## Calculate a 1-tailed p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1631700270157,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "WTJfsAI9ia4U",
    "outputId": "3f7c12e5-28ee-47f6-d3a1-8c734d80c3f3"
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate a one-tailed p-value based on your permuted samples (i.e.\n",
    "# or_perm) and store it in a variable called 'p_val_1t'\n",
    "if or_hat < 1:\n",
    "    p_val_1t = ...\n",
    "else:\n",
    "    p_val_1t = ...\n",
    "\n",
    "\n",
    "# The p-value can never be 0. If it comes out zero, what should we set it to instead?\n",
    "# (Ie, what is the most conservative estimate of the p-value in this case?)\n",
    "if p_val_1t == 0:\n",
    "    p_val_1t = ...\n",
    "\n",
    "p_val_1t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdeeRXY4iTs-"
   },
   "source": [
    "**QUESTION (Q7)**: What is our one-tailed p-value for the odds ratio?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhCHL_nUi4A_"
   },
   "source": [
    "## Calculate a 2-tailed p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1631700420966,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "VoxXxi8ajlFL",
    "outputId": "54f1c95b-6948-4d30-be39-7f3e26a76f2c"
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate a two-tailed p-value based on your permuted samples (i.e.\n",
    "# or_perm) and store it in a variable called 'p_val_2t'\n",
    "if or_hat < 1:\n",
    "    p_val_2t = ...\n",
    "else:\n",
    "    p_val_2t = ...\n",
    "\n",
    "if p_val_2t == 0:\n",
    "    p_val_2t = ...\n",
    "\n",
    "p_val_2t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ksL521ojYXJ"
   },
   "source": [
    "**QUESTION (Q8)**: What is our two-tailed p-value for the odds ratio?\n",
    "\n",
    "Philosophical interlude: The difference in implementation between\n",
    "2-tailed and 1-tailed p-value is pretty clear. The philosophical\n",
    "difference, somewhat less. If you accidentally coded a 2-tailed test and\n",
    "get a p value of, say,0.06, and then remember \"Oh! A 1-tailed test was\n",
    "actually more appropriate!\" (and it really is in that instance, not for a\n",
    "\"p-hacky\" reason) and obtain p ~ 0.03, there's a sudden shift in\n",
    "perspective on the data. But it's the same data, and you're performing\n",
    "more or less the same analysis. Does this seem even remotely reasonable?\n",
    "This very subtle distinction would have a pretty heavy impact on a\n",
    "statistics-naïve researcher. It can be helpful to think about edge cases\n",
    "like this, where our arbitrary thresholding statistical procedure leads\n",
    "to binarization of the same data into two categories which are\n",
    "interpreted in very different ways, and how we should consider data of\n",
    "this variety. Is it helpful to construct a new categorization, e.g.\n",
    "\"statistically significant (p small),\" \"unlikely to produce statistical\n",
    "significance (p biggish)\" and \"of uncertain relationship (p kinda\n",
    "small?)\" or does that just move the problem?\n",
    "\n",
    "See my article: https://www.eneuro.org/content/6/6/ENEURO.0456-19.2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DVIiKAmmvq5"
   },
   "source": [
    "## Compare with the Fisher Exact Test for Stroke data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1631701490956,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "q8MpajdgjWJg",
    "outputId": "1dafbbb5-eb46-4ce8-d1fe-39c06a2f5d57"
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "table = np.array([[n_stroke_rx, n_rx - n_stroke_rx], \n",
    "                  [n_stroke_ctrl, n_ctrl - n_stroke_ctrl]])\n",
    "\n",
    "# TODO: Calculate a 2-tailed p-value using Fisher's Exact Test\n",
    "odds_ratio, p_val = ...\n",
    "\n",
    "print(odds_ratio)\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc7V0THL-Rqi"
   },
   "source": [
    "This function doesn't return the confidence interval, unlike the Matlab version, so I implemented it myself below. See the equations [here](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717_ComparingFrequencies/PH717_ComparingFrequencies8.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1631702102848,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "B2yS6Z9A-Ocz",
    "outputId": "b5abb8f4-2837-4039-e1ea-3a7ad142be5a"
   },
   "outputs": [],
   "source": [
    "# Compute lower bound of 95% confidence interval\n",
    "\n",
    "# Compute the standard error of odds ratio\n",
    "se = np.sqrt( 1 / table[0, 0] + 1 / table[0, 1] + 1 / table[1, 0] + 1 / table[1, 1])\n",
    "\n",
    "# Get the confidence interval\n",
    "norm_inv = scipy.stats.norm.ppf((1 - my_alpha / 2))\n",
    "conf_interval_fisher = [odds_ratio*np.exp(-norm_inv*se), odds_ratio*np.exp(norm_inv*se)]\n",
    "\n",
    "print(conf_interval_fisher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sr7RkJ_lnWjY"
   },
   "source": [
    "**QUESTION (Q9)**: What p-value does Fisher's Exact Test give?\n",
    "\n",
    "**QUESTION (Q10)**: What is the lower bound of the 95% CI from Fisher's Exact\n",
    "Test?\n",
    "\n",
    "Be sure to compare this with your values from the bootstrap!\n",
    "\n",
    "**QUESTION (Q11)**: Save your final figure for the stroke data as a jpeg and\n",
    "upload it to the LC site.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjZzGuO7nrXs"
   },
   "source": [
    "## Repeat calculations for the heart attack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1631702227621,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "w_nuLZAFrzf3",
    "outputId": "b0a285da-f4d3-4745-ed31-1edecdbfbd10"
   },
   "outputs": [],
   "source": [
    "# Useful numbers for heart attack data\n",
    "n_rx = 11037  # number of patients in the treatment group (ASA)\n",
    "n_MI_rx = 104  # number of heart attacks (= MIs) in the treatment group\n",
    "n_ctrl = 11034  # number of patients in the control group (placebo)\n",
    "n_MI_ctrl = 189  # number of MIs in the control group\n",
    "\n",
    "# Generate the raw data\n",
    "n_rows = np.max([n_ctrl, n_rx])\n",
    "\n",
    "data = pd.DataFrame({'ctrl_grp': np.nan * np.ones((n_rows,)),\n",
    "                     'rx_grp': np.nan * np.ones((n_rows, )) })\n",
    "\n",
    "# TODO: create the raw data like before\n",
    "...\n",
    "\n",
    "data.head()\n",
    "\n",
    "# Odds ratio for MI data\n",
    "or_hat = ...\n",
    "\n",
    "print(or_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SW2Lc51drAXS"
   },
   "source": [
    "**QUESTION (Q12)**: What is the odds ratio, `or_hat`, for the heart attack data?\n",
    "\n",
    "TODO: Repeat the above analysis for the MI data. If you wrote\n",
    "everything in terms of `rx_grp` and `ctrl_grp`, then once you've generated\n",
    "the corresponding raw values for the MI data, you should be able to just\n",
    "re-run cells below the first dataframe creation/odds ratio computation without further edits to your code.\n",
    "\n",
    "**QUESTION (Q13)**: What is the bootstrap estimate of the 95% CI of the odds\n",
    "ratio for the heart attack data?\n",
    "\n",
    "**QUESTION (Q14)**: Can we reject H0 at an alpha of 0.05 for the heart attack data?\n",
    "\n",
    "**QUESTION (Q15)**: Based on the permutation test, what is your 1-sided\n",
    "p-value for the heart attack data?\n",
    "\n",
    "Be sure to compare the confidence intervals that you obtain\n",
    "through bootstrapping to those obtained with Fisher's Exact Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPH8_GdcCTCf"
   },
   "source": [
    "## Final thoughts on CIs and Hypothesis Testing\n",
    "\n",
    "There is a beautiful and important section on the relationship between\n",
    "confidence intervals and hypothesis tests in section 15.4 of E&T (p.\n",
    "214). \n",
    "\n",
    "Look at the top half of your figure. Key question: What value of alpha\n",
    "will make the lower end of the bootstrap confidence interval equal to 1?\n",
    "It is just the probability mass of the bootstrap distribution to the left\n",
    "of 1: sum(orStar <= 1) / nBoot. This gives us a bootstrap p-value of\n",
    "0.0807. (Compare this with our 1-tailed permutation-based p-value of\n",
    "0.0887.)\n",
    "\n",
    "Compare the top and bottom halves and consider this statement from E&T\n",
    "(p. 216): \"In this sense, the permutation p-value measures how far the\n",
    "observed estimate, orHat, is from 1, while the bootstrap p-value\n",
    "measures how far 1 is from orHat.\" (Remember that 1 is our null value\n",
    "for the odds ratio.)\n",
    "\n",
    "Which test is preferred? In general, the permutation test is the most\n",
    "rigorous way to test H0, since we are directly instantiating it by\n",
    "\"breaking\" the relationship we seek to test. In this case, we are\n",
    "randomly assigning the observed data to either the treatment or the\n",
    "control group. As E&T point out (p. 216): \"The permutation p-value is\n",
    "exact, while the bootstrap p-value is approximate.\" They conclude with\n",
    "what should become one of your statistical mantras (p. 218): \"When there\n",
    "is something to permute, it is a good idea to do so . . . .\"\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMsinqi4hxwLyCb5QshJAop",
   "collapsed_sections": [],
   "name": "TAD_Week3_etASAdemo_ng_solutions.ipynb",
   "provenance": [
    {
     "file_id": "1u-_JV6n8CZ1IleQ_RmvQ-Z1PFPu5-OL3",
     "timestamp": 1631702325319
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kB_ZxfYqxEs-"
   },
   "source": [
    "# Bootstrapping SE's and CI's with Grad School Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6MPwY-DxNE8"
   },
   "source": [
    "**Instructions:**\n",
    "\n",
    "The goal of this exercise is to become familiar with the technique of\n",
    "bootstrapping. Bootstrapping can be used to estimate the precision\n",
    "of statistics through resampling data. It is especially useful when there is no explicit formula available for the precision of a statistic, although it also works perfectly well even when there is. In other words, we can use bootstrapping to generate standard errors and\n",
    "confidence intervals on pretty much any kind of analysis.\n",
    "\n",
    "In this example, we will examine whether GRE scores predict future GPA.\n",
    "\n",
    "\n",
    "**What to do:**\n",
    "\n",
    "Login to learning catalytics and join the session for the\n",
    "module entitled \"Grad School Correlations\". You will answer a series of\n",
    "questions based on the guided programming below. Read through the comments and follow the instructions provided.\n",
    "In some cases you will be asked to answer a question, clearly indicated\n",
    "by 'QUESTION'. In other cases, you be asked to supply missing code,\n",
    "indicated by 'TODO'. The corresponding question in learning catalytics\n",
    "will be indicated in parentheses (e.g. Q1). If there is no 'Q#'\n",
    "accompanying a 'QUESTION' just type your answer into this script and\n",
    "discuss it with your team. \n",
    "\n",
    "Original source of exercise:\n",
    "Efron, B. & Tibshirani Robert, J. (1993) An introduction to the\n",
    "bootstrap. Chapman & Hall, London, see Table 3.2 on p. 21\n",
    "\n",
    "RTB wrote it 07 July 2019 (Kinsale, Ireland; Cork Distance Week,\n",
    "\"Champion of Champions\" day), ERBB translated to Python on 04 August, 2021. JP generated non-pandas version 25 Jun 2022.\n",
    "\n",
    "\n",
    "**Concepts covered:**\n",
    "1. Standard error of the mean calculated 3 ways:\n",
    "      a) formula, b) population sampling, c) bootstrap sampling\n",
    "2. Calculating correlation coefficients with 'corr'\n",
    "3. Bootstrapping standard errors with the built-in 'bootstrp' function\n",
    "4. Bootstrapping confidence intervals with the built-in 'bootci' function\n",
    "5. Parametric bootstrap by sampling from a bivariate normal distribution\n",
    "\n",
    "The data here are GRE (quant) and GPA (science) scores from a census of\n",
    "82 graduate programs in neuroscience. We also have a random sample of 15\n",
    "schools from this census as well. Note that these data were collected\n",
    "prior to August of 2011, so the GRE scores were scaled from 200 to 800.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mO6IbNwyFBj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Makes the figures look pretty\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(10, 5)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1631141466092,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "9AMQxUV8w_Bp",
    "outputId": "ce647950-6c85-40a9-b2f7-f159a727d3ca",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the data.\n",
    "# ds82 will be our \"population\", and ds15 will be our \"random sample\" from the population.\n",
    "# (That is, ds15 is a subset of ds82)\n",
    "ds82 = np.asarray(pd.read_excel('https://github.com/jonahpearl/TAD_python/blob/student_branch/data/Grad_School_82.xlsx?raw=true')) # All graduate programs (*census*)\n",
    "ds15 = np.asarray(pd.read_excel('https://github.com/jonahpearl/TAD_python/blob/student_branch/data/Grad_School_15.xlsx?raw=true')) # Random sample of 15\n",
    "\n",
    "# Define cols\n",
    "ID_COL = 0\n",
    "GRE_COL = 1\n",
    "GPA_COL = 2\n",
    "\n",
    "# Define a few constants\n",
    "n_boot = 10000\n",
    "n_samp = ds15.shape[0]\n",
    "n_census = ds82.shape[0]\n",
    "\n",
    "ds15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a simple linear regression on GPA vs GRE\n",
    "# See: https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html\n",
    "\n",
    "A = np.vstack([ds15[:,GRE_COL], np.ones(ds15.shape[0])]).T\n",
    "ds15_slope, ds15_intercept = np.linalg.lstsq(A, ds15[:,GPA_COL], rcond=None)[0]\n",
    "\n",
    "A = np.vstack([ds82[:,GRE_COL], np.ones(ds82.shape[0])]).T\n",
    "ds82_slope, ds82_intercept = np.linalg.lstsq(A, ds82[:,GPA_COL], rcond=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1629079361738,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "YYoQ1FEx0QvN",
    "outputId": "6c0c7434-856b-47ca-9274-53411210f3cf"
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "# Make the figure\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Plot the raw data\n",
    "plt.scatter(ds82[:,GRE_COL], ds82[:,GPA_COL], marker='+', color='k', label='Full census')\n",
    "plt.scatter(ds15[:,GRE_COL], ds15[:,GPA_COL], marker='o', color='r', facecolor='none', label='Random samples')\n",
    "\n",
    "# Plot the fit lines\n",
    "xvals = np.arange(450,750)\n",
    "plt.plot(xvals, xvals*ds15_slope + ds15_intercept, 'k', label='Full census fit line')\n",
    "plt.plot(xvals, xvals*ds82_slope + ds82_intercept, 'r', label='Random sample fit line')\n",
    "\n",
    "# Add legend based on our assigned labels\n",
    "plt.legend()\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('GRE Score (quant)')\n",
    "plt.ylabel('GPA (science)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WX-nnkhc6FE8"
   },
   "source": [
    "## Mean GRE score & standard error (SE)\n",
    "We start with something that is easy to compute directly. The reason we\n",
    "can do this is that, thanks to the Central Limit Theorem, we KNOW that\n",
    "the sampling distribution of the mean, regardless of the distribution of\n",
    "the original data from which the mean was calculated, will be normally\n",
    "distributed. Furthermore, we know that the standard deviation of the\n",
    "sampling distribution for the mean will be equal to the sample standard\n",
    "deviation divided by the square-root of the number of samples. This is\n",
    "the standard error of the mean.\n",
    "\n",
    "NOTE: There are two standard deviations at play here. The first is the\n",
    "standard deviation that we calculate from our sample--this is the sample\n",
    "standard deviation. But, in the next sections, we will be explicitly\n",
    "calculating the \"sampling distribution of the mean,\" which is the\n",
    "distribution of mean values we would get if we re-took our sample of 15\n",
    "many different times and calculated a new sample mean each time. The\n",
    "standard deviation of the sampling distribution of the mean is, by\n",
    "definition, the standard error. In fact, and this is very important to\n",
    "just flat out memorize until practice makes it intuitive: THE STANDARD\n",
    "ERROR OF ANY STATISTIC IS THE STANDARD DEVIATION OF THE SAMPLING\n",
    "DISTRIBUTION OF THAT STATISTIC. The mean is a special case where we can\n",
    "use a handy-dandy formula to calculate the standard deviation of the\n",
    "sampling distribution (i.e. the standard error of the mean) based on the\n",
    "standard deviation of our single sample.\n",
    "\n",
    "*Python note*: Pandas and matlab both divide by n - 1 when they compute standard deviation. In numpy, the std is computed by dividing by n, unless you change the `ddof` (delta degrees of freedom) argument to be 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the mean GRE score for your sample. \n",
    "# Then calculate the standard error of the mean (SEM) using the formula: SEM = std(sample) / sqrt(N)\n",
    "\n",
    "mean_GRE = ...\n",
    "sem_GRE = ...\n",
    "\n",
    "sem_GRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afSZZVt_6U6T"
   },
   "source": [
    "\n",
    "**QUESTION (Q1)**: What is the value of semGRE to 2 decimal places?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDRn4cGgkAX3"
   },
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jxAbDx8s6fW"
   },
   "source": [
    "## \"True\" standard error by sampling from the population\n",
    "\n",
    "Here, we \"bootstrap\" from the entire population, which is a contrived scenario just for sake of comparison. This isn't really bootstrapping!!\n",
    "\n",
    "Normally, we don't have access to the entire population, and so we won't be able to do this!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 2222,
     "status": "ok",
     "timestamp": 1629079364947,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "JdjEr3MH6x5F",
    "outputId": "d6178818-cc84-4f3e-ddc0-45beb48a6982"
   },
   "outputs": [],
   "source": [
    "all_means = np.zeros(n_boot,)\n",
    "\n",
    "np.random.seed(123) # for consistency across class; You would not normally do this.\n",
    "\n",
    "for k in range(n_boot):\n",
    "\n",
    "    # TODO: Draw n_boot samples of size 15 (n_samp) from the CENSUS of 82, each time \n",
    "    # calculating the sample mean. Save each mean in 'all_means'\n",
    "    all_means[k] = ...\n",
    "\n",
    "# Look at the sampling distribution of the mean\n",
    "plt.hist(all_means, bins = 10)\n",
    "plt.xlabel('mean GRE score')\n",
    "plt.ylabel('# of samples of size 15')\n",
    "plt.title('Distribution of means, sampling from CENSUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1629079364949,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "G9ZVbJFIwgyF",
    "outputId": "763a2363-9d73-4479-92d6-d8e2042ca8ae"
   },
   "outputs": [],
   "source": [
    "# TODO: calculate the standard error of the mean from this sample:\n",
    "sem_GRE_samp = ...\n",
    "\n",
    "sem_GRE_samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcSMxd1Cv048"
   },
   "source": [
    "**QUESTION** (Q2): What is the value of `sem_GRE_samp` to 2 decimal places? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6-B1eoKwA66"
   },
   "source": [
    "## Bootstrap standard error by sampling from the sample\n",
    "\n",
    "Calculate another SEM as you did above, but now, instead of drawing your samples from the CENSUS, you will draw your samples from the SAMPLE. This is a more realistic simulation of what you might do in a scientific setting, since you will normally not have access to the full population.\n",
    "\n",
    "You do this by sampling WITH REPLACEMENT from your original actual sample of the 15 graduate schools. This is the essence of the bootstrap!\n",
    "\n",
    "Hint: you should only have to change one key aspect of your code from above.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "executionInfo": {
     "elapsed": 2634,
     "status": "ok",
     "timestamp": 1629079367556,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "IPvsyV24vQN3",
    "outputId": "e1ee6fba-9a1d-4cf3-ab8e-ff8507a290d1"
   },
   "outputs": [],
   "source": [
    "all_means_bootstrap = np.zeros(n_boot,)\n",
    "\n",
    "np.random.seed(123) \n",
    "for k in range(n_boot):\n",
    "\n",
    "    # TODO: sample with replacement from the sample and get mean\n",
    "    all_means_bootstrap[k] = ...\n",
    "\n",
    "# Visualize the sampling distribution of the mean\n",
    "plt.hist(all_means_bootstrap, bins = 10)\n",
    "plt.xlabel('mean GRE score')\n",
    "plt.ylabel('# of samples of size 15')\n",
    "plt.title('Distribution of means, sampling from SAMPLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1629079367556,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "h2Z9XUzNPyXk",
    "outputId": "7745f79d-afdd-46fd-b0b4-ba333045da0e"
   },
   "outputs": [],
   "source": [
    "# TODO: calculate the standard error of the mean from the bootstrap \n",
    "#      sampling distribution of the means\n",
    "sem_GRE_boot = ...\n",
    "\n",
    "sem_GRE_boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyFFIbbPxR0F"
   },
   "source": [
    "**QUESTION** (Q3): What is the value of `sem_GRE_boot` to 2 decimal places? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cn4dRCoExWUT"
   },
   "source": [
    "**QUESTION** (Q4): What is the error (in %) of the bootstrap estimate w/r/t that of the formula? Calculate in next cell. Round to the nearest whole number in %.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1629079367559,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "OoS6BjN3xajh",
    "outputId": "62b0b0c6-65bd-4775-b4d4-f48b1f578208"
   },
   "outputs": [],
   "source": [
    "# TODO: Compare your bootstrap estimate of the SE with that from the formula\n",
    "percent_error = ...\n",
    "\n",
    "percent_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lIvcxVoxuk2"
   },
   "source": [
    "# Correlation of GRE and GPA in census and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1629079367560,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "Q7Zb06Viwhon",
    "outputId": "5c91638f-c72c-4955-814b-fba914b4f3c8"
   },
   "outputs": [],
   "source": [
    "# TODO: Use np.corrcoef() to calculate the correlation coefficients between GPA and GRE in both ds15 and ds82 \n",
    "\n",
    "rho_hat_82 = \n",
    "rho_hat_15 = \n",
    "\n",
    "print(rho_hat_82)\n",
    "print(rho_hat_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgyGkLj5x1G_"
   },
   "source": [
    "**QUESTION (Q5)**: What is a correlation coefficient?\n",
    "\n",
    "**QUESTION (Q6)**: What is the correlation coefficient for the census? \n",
    "\n",
    "**QUESTION (Q7)**: Based on the correlation coefficient and the graph, would you guess GRE score and GPA are correlated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kvUWZUOy6UE"
   },
   "source": [
    "Standard error for the correlation coefficient (sampled from sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTzj31X1aq_F"
   },
   "source": [
    "Unlike for the mean, there is no handy, dandy formula for the standard error of a correlation coefficient. Now we really do need the bootstrap!\n",
    "\n",
    "Get a bootstrap sample of correlation coefficients the old fashioned way, using a 'for' loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 8866,
     "status": "ok",
     "timestamp": 1629079376416,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "3o4cYpZqx5IX",
    "outputId": "991f1265-354f-48d7-857e-43f9e114ad0b"
   },
   "outputs": [],
   "source": [
    "np.random.seed(123) # for reproducibility\n",
    "\n",
    "rhos_sample = np.zeros(n_boot,)\n",
    "\n",
    "for k in range(n_boot):\n",
    "\n",
    "    # TODO: Randomly sample n_samp rows from ds15 with replacement\n",
    "    rows_to_use = ...\n",
    "    sampled_rows = ...\n",
    "    \n",
    "    # TODO: Compute the correlation of GRE score and GPA for this sample\n",
    "    rhos_sample[k] = ...\n",
    "\n",
    "_ = plt.hist(rhos_sample, bins=100)\n",
    "\n",
    "# Label the plot\n",
    "# (gca() is \"get current axis;\" equivalent to doing plt.xlabel() and plt.ylabel() separately)\n",
    "plt.gca().set(xlabel = 'Correlation coefficient', ylabel = 'Probability')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1629079376417,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "Ba51UEIpXVbV",
    "outputId": "b1e04d8d-5d2b-4d1b-ee8b-e55a2707cd7f"
   },
   "outputs": [],
   "source": [
    "# Compute standard error of our correlation coefficient\n",
    "se_rho_boot = ...\n",
    "\n",
    "se_rho_boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt4DvlubzBhD"
   },
   "source": [
    "**QUESTION (Q8)**: What is the value of `se_rho_boot` (referred to as `se_rho_boot_FL` in learning catalytics) to 4 decimal places?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1629079376418,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "Q5QB1kpuXPk5",
    "outputId": "711edbaf-4140-4e9d-a127-306b1b43178d"
   },
   "outputs": [],
   "source": [
    "# Compute mean of distribution\n",
    "mean_rho_boot = ...\n",
    "\n",
    "mean_rho_boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoxTv3cPX439"
   },
   "source": [
    "**QUESTION (Q9)**: What is the mean of this distribution to 2 decimal places?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jSaNIn9X7Ck"
   },
   "source": [
    "Q10/Q11/Q12 are specific to Matlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMJCBxtt2NO9"
   },
   "source": [
    "## \"True\" standard error (sample from census)\n",
    "\n",
    "As we did above for the mean, we can take advantage of the fact that we\n",
    "have data for the complete population (i.e. census), and see how our\n",
    "estimate of rho is distributed when we repeatedly sample from the\n",
    "population. That is, instead of re-sampling our sample of 15 with\n",
    "replacement, we sample the 'population' of 82 graduate schools with\n",
    "replacement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 9668,
     "status": "ok",
     "timestamp": 1629079386081,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "bIUzE5gZzDbS",
    "outputId": "278bee44-2526-4a3f-e6b2-2409f5a5884c"
   },
   "outputs": [],
   "source": [
    "np.random.seed(123) # for reproducibility\n",
    "\n",
    "rhos_census = np.zeros(n_boot,)\n",
    "\n",
    "for k in range(n_boot):\n",
    "\n",
    "    # TODO: Randomly sample n_samp rows from ds15 with replacement\n",
    "    rows_to_use = ...\n",
    "    sampled_rows = ...\n",
    "    \n",
    "    # TODO: Compute the correlation of GRE score and GPA for this sample\n",
    "    rhos_census[k] = ...\n",
    "\n",
    "_ = plt.hist(rhos_census, bins=100, alpha=0.5, label='Census', color='C1')  # you can access the matplotlib colors with \"CN\", 0 <= N <= 9\n",
    "_ = plt.hist(rhos_sample, bins=100, alpha=0.5, label='Sample', color='C0')\n",
    "plt.legend()\n",
    "\n",
    "# Label the plot\n",
    "# (gca() is \"get current axis;\" equivalent to doing plt.xlabel() and plt.ylabel() separately)\n",
    "plt.gca().set(xlabel = 'Correlation coefficient', ylabel = 'Probability')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XWIXUNSVu8E"
   },
   "source": [
    "**QUESTION (Q13)**: How does this distribution compare to the bootstrapped resampling of 15 schools? Consider the general skew, spread, location (i.e. mean,median) of the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI7hk7_wW5KN"
   },
   "source": [
    "**Question (Q14)**: Compute the standard error of the correlation coefficient for the samples bootstrapped from the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1629079386082,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "z4oNecE22pAU",
    "outputId": "6230c187-24e8-4a04-bbea-fb60fb0123fe"
   },
   "outputs": [],
   "source": [
    "# TODO: Compute the standard error of the correlation coefficient for the samples \n",
    "# bootstrapped from the population.\n",
    "se_rho_boot_TS = ...\n",
    "\n",
    "se_rho_boot_TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6m_7RBoeXBcm"
   },
   "source": [
    "## The 'parametric bootstrap' (p. 53 of E&T)\n",
    "\n",
    "\"Instead of sampling with replacement from the data, we draw B samples of\n",
    "size n from the parametric estimate of the population.\"\n",
    "\n",
    "The parametric bootstrap differs from the traditional bootstrap in that\n",
    "we fit a model to the data and then draw random numbers from this fitted\n",
    "model, rather than resampling the data itself. Why might one want to do\n",
    "this? Well, in rare instances when one wants to bootstrap the SE for some\n",
    "sample 'outlier', such as the 'min' or 'max', the data-driven bootstrap\n",
    "will fail. (Try this and see for yourself what is going on.) In such\n",
    "cases, the parametric bootstrap gets it right.\n",
    "\n",
    "In this case, we will assume that the population has a bivariate normal\n",
    "distribution, with means `mu_hat` and a covariance matrix of `cov_hat`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVvx1xWGWpYU"
   },
   "outputs": [],
   "source": [
    "mu_hat = ds15[:,[GRE_COL, GPA_COL]].mean(axis=0)\n",
    "cov_hat = np.cov(ds15[:,[GRE_COL, GPA_COL]], rowvar=False) \n",
    "cov_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Recall covariance is un-normalized correlation, so the diagonals aren't 1, but the variance of each variable.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TlUo3n_YScC"
   },
   "source": [
    "Using what we learned from bootstrapping, create a 'for' loop that uses the `np.random.multivariate_normal` function to draw n_boot samples of size `n_samp` from a bivariate normal distribution with mean `mu_hat` and covariance `cov_hat`. Compute the correlation coefficient for each sample and store in `rhos_parametric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CV34bzTrXkZe"
   },
   "outputs": [],
   "source": [
    "rhos_parametric = np.zeros((n_boot,))\n",
    "\n",
    "np.random.seed(123)\n",
    "for k in range(n_boot):\n",
    "\n",
    "    # TODO: Draw samples from normal distribution\n",
    "    R = ...\n",
    "\n",
    "    # TODO: Compute correlation coefficient (use np.corrcoef)\n",
    "    rhos_parametric[k] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmYg5Cz5aBJD"
   },
   "source": [
    "**QUESTION (Q15)**: What is the standard error of the correlation coefficient as determined by parametric bootstrapping? Compute in code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1629079390652,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "Na8FTZFoXlC8",
    "outputId": "dcec7db7-bc34-4159-d753-dbc73ed86b8e"
   },
   "outputs": [],
   "source": [
    "# TODO: get standard error of correlation coefficient from parametric bootstrapping\n",
    "se_rho_PBS = ...\n",
    "\n",
    "se_rho_PBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 1445,
     "status": "ok",
     "timestamp": 1629079392084,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "8L7ffhrEeZ6-",
    "outputId": "a089167d-e0ca-4036-c404-4e7e28d2fadb"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(rhos_parametric, bins=100, alpha=0.5, label='Parametric', color='C2')\n",
    "_ = plt.hist(rhos_census, bins=100, alpha=0.5, label='Census', color='C1')  # you can access the matplotlib colors with \"CN\", 0 <= N <= 9\n",
    "_ = plt.hist(rhos_sample, bins=100, alpha=0.5, label='Sample', color='C0')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Label the plot\n",
    "plt.gca().set(xlabel = 'Correlation coefficient', ylabel = 'Probability')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1629079392085,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "MDsdfyq4fOqp",
    "outputId": "10c5e73d-556c-45cf-8984-558b98f1f150"
   },
   "outputs": [],
   "source": [
    "print(se_rho_boot)\n",
    "print(se_rho_boot_TS)\n",
    "print(se_rho_PBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUrUS4GybZUB"
   },
   "source": [
    "**QUESTION (Q16)**: How does the SE of the correlation coefficient compare to our other bootstrapping strategies? If it's different, why do you think this may be so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGbA0ohqs1JQ"
   },
   "source": [
    "\n",
    "Answer: When a model fits the data properly, simulating from the model as we \n",
    "have above generates more accurate estimates for the same sampling n than \n",
    "re-sampling our data. Thus, the standard error for the correlation \n",
    "coefficient is smaller here than our other bootstrapping methods. \n",
    "HOWEVER, this assumption only works if our model is appropriate. If \n",
    "inappropriate, we will converge on an incorrect answer. This is one \n",
    "example of a trade-off between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNHNSuczbuDA"
   },
   "source": [
    "For good measure, note that we can also plot the histograms in a grouped manner, if we pass the arrays as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1629079392990,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "P8tDMH5Dgjyv",
    "outputId": "09b0f924-9123-46a3-dfc2-eef00e8c5d6a"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist([rhos_sample, rhos_census, rhos_parametric], bins=20, label=['Sample', 'Census', 'Parametric'])\n",
    "plt.legend()\n",
    "plt.gca().set(xlabel = 'Correlation coefficient', ylabel = 'Probability')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Liy3ZKxyfR50"
   },
   "source": [
    "# Confidence intervals\n",
    "\n",
    "We have used several different strategies to create sampling\n",
    "distributions:\n",
    "  1. Repeated sampling from the entire population.\n",
    "  2. Repeated re-sampling from our original sample (bootstrap)\n",
    "  3. Repeated sampling from a population defined by parameters derived\n",
    "     from our original sample (parametric bootstrap)\n",
    "\n",
    "But in each case, we have generated an estimate of the sampling\n",
    "distribution for a given statistic. Thus far, we have used these\n",
    "distributions to generate a single estimate of precision: the standard\n",
    "error. However, we can use these same distributions to calculate other\n",
    "measures of precision, such as confidence intervals. After all, under\n",
    "normal assumptions, a standard error is a kind of confidence interval,\n",
    "since we expect about 68% of the distribution to be within +/- s.d. That\n",
    "is, for example, the SEM can be thought of as defining a 68% CI for our\n",
    "estimate of the mean. But we can go further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kA249ISHjs8x"
   },
   "source": [
    "## CI by asymptotic normal distribution theory\n",
    "\n",
    "Since the std. error is the 68% CI, we can get any other CI by just calculating the appropriate number of standard deviates from the normal distribution. Let's use this to get 95% CI's based on our bootstrap sample (rhos_sample) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZb_ZqjZlFll"
   },
   "outputs": [],
   "source": [
    "# This is our mean correlation\n",
    "mean_rho_boot = rhos_sample.mean()\n",
    "\n",
    "# This is our 68% CI\n",
    "se_rho_boot = rhos_sample.std(ddof=1)\n",
    "\n",
    "# Set alpha for a 95% CI\n",
    "my_alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz4zI4N7msdg"
   },
   "source": [
    "You probably remember that a 95% CI is +/- 1.96 standard deviates. So we\n",
    "could calculate our CI as `mean_rho_boot` +/- 1.96*`se_rho_boot`. But say we\n",
    "wanted to be able to calculate any arbitrary confidence interval. For a\n",
    "99% CI, we would set `my_alpha` to 0.01.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjqXP01jltCD"
   },
   "outputs": [],
   "source": [
    "# TODO: Write a line of code that will convert a desired CI, \n",
    "#       expressed as my_alpha to the appropriate number of standard deviates. \n",
    "#       Use `norm` from scipy.stats, imported below\n",
    "from scipy.stats import norm\n",
    "num_std_deviates = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G22s-OFkwJve"
   },
   "source": [
    "**QUESTION (Q17)**: What is `num_std_deviates` for `my_alpha` = 0.001?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1629079393524,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "uqEaEA3UuoTf",
    "outputId": "91a3060e-3aa4-46ca-fb0c-de0994eafa7f"
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate the lower and upper bounds for the 95% CI\n",
    "rho95_CI_low = ...\n",
    "rho95_CI_hi = ...\n",
    "\n",
    "print(rho95_CI_low)\n",
    "print(rho95_CI_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQmfUlHqwmNp"
   },
   "source": [
    "**QUESTION (Q18)**: What is the value of `rho95_CI_hi`?\n",
    "\n",
    "**QUESTION (Q19)**: Does this value make sense? Why or why not?\n",
    "\n",
    "Whoops, we have a correlation value over 1! That happens because the normal distribution's density extends out to infinity, whereas correlations only range from -1 to 1. We could fix this by applying a transformation to move the r values from [-1,1] to [-inf, inf] (see Fisher Transformation subsection at https://stats.stackexchange.com/questions/226380/derivation-of-the-standard-error-for-pearsons-correlation-coefficient). We could also use the percentile method, which is the way we choose below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1629079393855,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "ZMemJk-ioB40",
    "outputId": "8659c4ef-287c-4734-f756-7d32dc2991f1"
   },
   "outputs": [],
   "source": [
    "# Plot of distribution of bootstrapped correlation coefficients\n",
    "_ = plt.hist(rhos_sample, bins=100)\n",
    "\n",
    "# Add vertical lines to mark mean, CIs\n",
    "ylims = plt.ylim()\n",
    "plt.vlines(mean_rho_boot, *ylims, color='k', label='Mean')\n",
    "\n",
    "# # TODO: Draw lines for the mean and 95% CI on our histogram. Be sure to label them!\n",
    "plt.vlines(...)\n",
    "plt.vlines(...)\n",
    "\n",
    "plt.legend()\n",
    "plt.gca().set(xlabel = 'Correlation coefficient', ylabel = 'Probability',\n",
    "       title = 'Distribution of rho values: boostrap',\n",
    "       xlim = [0.15, 1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQef0A27zTjt"
   },
   "source": [
    "##  CI by percentile method\n",
    "\n",
    "In this case, we generated 10,000 samples, so a more intuitive, brute-force way to calculate the 95% CI is just to sort our bootstrap replicates and then find the values corresponding to 250th and the 9750th index in the sorted array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1629079393856,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "ikQHd5ydzQ5N",
    "outputId": "f9c97120-8c91-4ca4-811c-c13bcb79c608"
   },
   "outputs": [],
   "source": [
    "# Sort our bootstrap replicates\n",
    "bs_rhos_sorted = np.sort(rhos_sample)\n",
    "\n",
    "# TODO: find indices corresponding to lower and upper bounds\n",
    "idx_lo = ...\n",
    "idx_hi = ...\n",
    "\n",
    "# Get high and low bounds using percentiles\n",
    "rho95_CI_percentile_low = bs_rhos_sorted[int(idx_lo)]\n",
    "rho95_CI_percentile_hi = bs_rhos_sorted[int(idx_hi)]\n",
    "\n",
    "print(rho95_CI_percentile_low)\n",
    "print(rho95_CI_percentile_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i19Hqlr-0L8i"
   },
   "source": [
    "**QUESTION (Q20)**: What is the lower bound of the 95% CI?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1629079394536,
     "user": {
      "displayName": "Ella Batty",
      "photoUrl": "",
      "userId": "17939168843900203228"
     },
     "user_tz": 240
    },
    "id": "Ku_OOaqurbXf",
    "outputId": "d5109e5b-9baf-4fc3-98ab-d5a93abc4176"
   },
   "outputs": [],
   "source": [
    "# Plot of distribution of bootstrapped correlation coefficients\n",
    "_ = plt.hist(rhos_sample, bins=100)\n",
    "\n",
    "# Add vertical lines to mark mean, CIs\n",
    "ylims = plt.ylim()\n",
    "plt.vlines(mean_rho_boot, *ylims, color='k', label='Mean')\n",
    "\n",
    "# # TODO: Add lines for the percentile method CI's \n",
    "plt.vlines(...)\n",
    "plt.vlines(...)\n",
    "\n",
    "plt.legend()\n",
    "plt.gca().set(xlabel = 'Correlation coefficient', ylabel = 'Probability',\n",
    "       title = 'Distribution of rho values: boostrap',\n",
    "       xlim = [0.15, 1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0rUEKE-sNYA"
   },
   "source": [
    "Question 21 is specific to Matlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOSTmn_Q1Slm"
   },
   "source": [
    "**QUESTION (Q22)**: Think about this confidence interval and your earlier guess about whether GRE score and GPA are correlated. How can you use this to generate a hypothesis test? (i.e. Can we say that GRE and GPA are significantly correlated at p < 0.05?)\n",
    "\n",
    "**QUESTION (Q23)**: Today we've explored bootstrapping as a way to estimate standard errors and confidence intervals for means and correlation coefficients. Which of these measures are the most robust across our different ways of bootstrapping and estimating? Which are more sensitive to the method we chose?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeSmDrMTsupT"
   },
   "source": [
    "Answer: In general, measures like means and standard errors are pretty\n",
    "robust and we can estimate them pretty precisely with only a few hundred\n",
    "bootstrap replicates. However, the closer we get to the tails of the\n",
    "distribution (e.g. estimating 95% or 99% Confidence Intervals) the more\n",
    "replicates we need to get a robust estimate and the more things like bias\n",
    "correction and bootstrapping method matter. For example, Efron &\n",
    "Tibshirani recommend a minimum of several thousand bootstrap replicates\n",
    "when estimating confidence intervals.\n",
    "\n",
    "NOTE: An entire chapter of E&T is devoted to \"Better bootstrap confidence\n",
    "intervals,\" where they describe the method known as \"bias corrected and\n",
    "accelerated\" (or BCA), which is the default method for 'bootci'. See\n",
    "chapters 14 and 22 of E&T if you crave mathematical details."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPs4wBURDI4DayF3pmOybHN",
   "collapsed_sections": [],
   "name": "TAD_Week2_etBootStrapIntro_Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
